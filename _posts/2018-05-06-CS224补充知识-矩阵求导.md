---
layout:     post
title:      CS224学习笔记补充-矩阵求导
subtitle:   信息熵
date:       2018-05-06
author:     徐清华
header-img: img/post-bg-ios9-web.jpg
catalog: 	 true
tags:
    -CS224
    -矩阵求导
---

#1.Introduction
&emsp;线性代数在机器学习以及深度学习中扮演着重要的角色,涉及到向量的运算,矩阵的运算,特征值特征向量的求解等.在这里对于这些基础知识不再赘述,本文的重点在于矩阵的求导.本文主要参考吴恩达CS229课程的补充材料.

#2.Gradient
&emsp;假设存在函数 f : R m×n → R 以一个m×n的矩阵作为输入,以**实数值**作为函数的输出,那么这个函数的关于矩阵A的梯度可以表示为
![image.png](https://upload-images.jianshu.io/upload_images/12011882-8d2343f5b8e4168a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
&emsp;也可以表示成下面这种形式
![image.png](https://upload-images.jianshu.io/upload_images/12011882-bc46f37808740773.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
&emsp;可以很容易看出,梯度的维度是和被求导矩阵的维度是一致的.因此,针对向量的特殊情况,就有如下表达式:
![image.png](https://upload-images.jianshu.io/upload_images/12011882-c589da0da797581d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
&emsp;需要注意的一点是,上述性质只试用于函数是**实值函数**的情况,如果函数的值是向量或者矩阵,则不存在上述的性质.
&emsp;此外,矩阵的梯度仍然具有下列两个性质:
![image.png](https://upload-images.jianshu.io/upload_images/12011882-3c2c4c87ff432d59.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
------------
&emsp;现在,我们需要讨论一个在出现矩阵梯度时不可避免的问题:符号的歧义.理论上讲,梯度只是多元函数在求偏导数的一个很自然的扩展应用.然而,在实际操作时我们经常会遇到符号歧义的情况.举例来说,矩阵A ∈ R<sup> m×n</sup> 是一个固定系数的矩阵,向量b∈ R<sup>m</sup>是一个固定系数的向量,函数 f : R<sup>m</sup> → R 是一个输入为m维向量的实值函数.f的具体定义为: f (z) = z<sup>T</sup>z, 所以对应的梯度是∇ <sub>z</sub> f (z) = 2z.至此都没有什么问题,但是考虑如下表达式:
![image.png](https://upload-images.jianshu.io/upload_images/12011882-1c5887e00d39ed39.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
&emsp;我们该怎样理解这样一个表达式,最起码可以有两种理解方式:
&emsp;1.参考前文所写,输入是向量,结果是实值,梯度是∇ <sub>z</sub> f (z) = 2z,则有
![image.png](https://upload-images.jianshu.io/upload_images/12011882-7aca753389e2a171.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
&emsp;2.如果把这个函数看做是x的函数,那么梯度求导就应是针对x的求导,A应该看作是常数,梯度结果就应该是
![image.png](https://upload-images.jianshu.io/upload_images/12011882-6064e98f15bb0f9a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
&emsp;我们能够看出,问题主要在于针对谁在求梯度,所以在表示梯度的时候最好使用下表对梯度的求导对象进行标注.

#3.Hessian
假设函数 f : R<sup>n</sup> → R 是输入为n维的向量,输出为实值的函数,那么关于向量x的Hessian矩阵可以写作,∇ <sub>2</sub>x f (x) 或者简单的表示为H,具体的形式如下
matrix of partial derivatives,
![image.png](https://upload-images.jianshu.io/upload_images/12011882-33fb65f86e7e0471.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
&emsp;Hessian可以看做是二阶导,Gradient可以看做是一阶导数.
#4.Useful deductions
##1.Linear Algebra Properties
![image.png](https://upload-images.jianshu.io/upload_images/12011882-680ee8c642d692e1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
![image.png](https://upload-images.jianshu.io/upload_images/12011882-83e5e994ffe73e9d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
###2.Matrix Derivatives
![](https://upload-images.jianshu.io/upload_images/12011882-9a314f61a476effc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


