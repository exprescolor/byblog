---
layout:     post
title:      大数据处理技巧
subtitle:   
date:       2023-01-30
author:     Joey
header-img: img/post-bg-ds.jpg
catalog: true
tags:
    - python
    - 人工智能
    - 数据分析
---

- 使用pandas工具包可以处理千万级别的数据量，但读取过于庞大的数据特征时，经常会遇到内存溢出等问题。估计绝大多数读者使用的笔记本电脑都是8GB内存，没关系，这里教给大家一些技巧，使其占用更少的内存。

```
    gl = pd.read_csv('data.csv')
    gl.shape //展示一共的数据量
    gl.info(memory_usage = 'deep') // 打印出来数据占用内存量
```

- 不同类型的内存占用量

```
    for dtype in ['float64', 'int64', 'object']:
        selected_dtype = gl.slect_dtypes(include = [dtype])
        mean_usage_b = selected_dtype.memory_usage(deep=True).mean()
        mean_usage_mb = mean_usage_b.1024*2
        print('平均内存占用', dtype.,eam_usage_mb)
```

mem_usage()函数的主要功能就是计算传入数据的内存占用量


> 本文首次发布于 [Joey Blog](http://qiaoyu113.github.io), 作者 [@乔宇(Joey)](http://github.com/qiaoyu113) ,转载请保留原文链接..