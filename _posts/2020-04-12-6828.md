---
layout:     post   				    # 使用的布局（不需要改）
title:      6828-lab4（4.17更新）		# 标题 
#subtitle:   脚本，xss #副标题
date:       2020-04-12 				# 时间
author:     s-seven 						# 作者
header-img: img/post-bg-2015.jpg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - 6828
---

#Lab 4: Preemptive Multitasking

在这个实验中，我们将在多个同时活动的用户模式环境中实现先发制人的多任务处理。

在第A部分中，我们将向jos添加多处理器支持、实现循环调度并添加基本的环境管理系统调用(创建和破坏环境的调用以及分配/映射内存的调用)。

在第B部分中，我们将实现一个类unix的fork()，它允许用户模式环境创建自身的副本。

最后，在第C部分中，我们将添加对进程间通信(IPC)的支持，允许不同的用户模式环境显式地相互通信和同步。我们还将添加对硬件时钟中断和抢占的支持。

在切换分支时，我遇到了一个问题：

```
s-seven@sseven-virtual-machine:~/lab$ git pull
error: 您尚未结束您的合并（存在 MERGE_HEAD）。
提示：请在合并前先提交您的修改。
fatal: 因为存在未完成的合并而退出。
```

搜索相关问题后输入`rm .git/MERGE_HEAD`解决这个

```
git checkout -b lab4 origin/lab4
error: 您对下列文件的本地修改将被检出操作覆盖：
	kern/env.c
	kern/pmap.c
	kern/syscall.c
	kern/trap.c
	kern/trapentry.S
	lib/printfmt.c
请在切换分支前提交或贮藏您的修改。
终止中
```

原来我这些没有提交，

```
s-seven@sseven-virtual-machine:~/lab$ git stash
保存工作目录和索引状态 WIP on lab3: a9d7717 Lab 3
```

保存一下就好了

悲伤的是，微博图床不能用了。。。

然后发现多了下面的内容：

| `kern/cpu.h`      | Kernel-private definitions for multiprocessor support        |
| ----------------- | ------------------------------------------------------------ |
| `kern/mpconfig.c` | Code to read the multiprocessor configuration                |
| `kern/lapic.c`    | Kernel code driving the local APIC unit in each processor    |
| `kern/mpentry.S`  | Assembly-language entry code for non-boot CPUs               |
| `kern/spinlock.h` | Kernel-private definitions for spin locks, including the big kernel lock |
| `kern/spinlock.c` | Kernel code implementing spin locks                          |
| `kern/sched.c`    | Code skeleton of the scheduler that you are about to implement |

## Part A: 多处理器支持和多任务协作

​		在本实验的第一部分中，我们将首先扩展JOS，使其在多处理器系统上运行，然后实现一些新的JOS内核系统调用，以允许用户级环境创建额外的新环境。我们还将实现协作循环调度，允许内核在当前环境自动放弃CPU(或退出)时从一个环境切换到另一个环境。在C部分的后面部分，您将实现抢占式调度，它允许内核在经过一段时间之后，即使环境不合作，也可以从环境中重新获得对CPU的控制。

### Multiprocessor Support

​		我们将使JOS支持“对称多处理”(SMP)，这是一种多处理器模型，其中所有cpu都可以对系统资源(如内存和I/O总线)进行等效访问。虽然SMP中的所有cpu在功能上都是相同的，但在引导过程中它们可以分为两种类型:引导处理器(bootstrap processor, BSP)负责初始化系统和引导操作系统;只有在操作系统启动并运行之后，BSP才会激活应用程序处理器(APs)。哪个处理器是BSP是由硬件和BIOS决定的。到目前为止，您所有现有的JOS代码都是在BSP上运行的。

​		在SMP系统中，每个CPU都有一个相应的本地APIC (LAPIC)单元。LAPIC单位负责在整个系统中提供中断。LAPIC还为其连接的CPU提供唯一的标识符。在本实验室，我们利用了LAPIC单元的以下基本功能(以kern/ LAPIC .c表示):

- 读取LAPIC标识符(APIC ID)来告诉我们的代码当前在哪个CPU上运行(参见cpunum())。

- 将启动处理器间中断(IPI)从BSP发送到APs以打开其他cpu(参见lapic_startap())。

- 在第C部分中，我们对LAPIC的内置计时器进行编程，以触发时钟中断来支持先发制人的多任务处理(参见apic_init())。

处理器使用内存映射I/O (MMIO)访问它的LAPIC。在MMIO中，物理内存的一部分被硬连接到一些I/O设备的寄存器，因此通常用于访问内存的加载/存储指令也可以用于访问设备寄存器。我们已经看到了物理地址0xA0000处的一个IO漏洞(我们使用它来写入VGA显示缓冲区)。LAPIC位于一个从物理地址0xFE000000开始的洞中(32MB短于4GB)，因此对于我们使用通常的KERNBASE直接映射访问它太高了。JOS虚拟内存映射在MMIOBASE留下了4MB的空白，所以我们有地方来映射这样的设备。由于后来的实验引入了更多的MMIO区域，我们将编写一个简单的函数来从这个区域分配空间并将设备内存映射到它。

### 练习1

在kern/pmap.c中实现mmio_map_region。要了解如何使用它，请查看kern/lapic.c中lapic_init的开头。在运行mmio_map_region测试之前，您还必须进行下一个练习。

所以我们先看一看kern/lapic.c中的lapic_init（）：

```c
void
lapic_init(void)
{
	if (!lapicaddr)
		return;

	// lapicaddr是LAPIC的4K MMIO区域的物理地址。将它映射到虚拟内存中，以便我们可以访问它。
	lapic = mmio_map_region(lapicaddr, 4096);

	// APIC;设置伪中断向量。
	lapicw(SVR, ENABLE | (IRQ_OFFSET + IRQ_SPURIOUS));

	// 定时器从lapic[TICR]开始以总线频率重复地倒数，然后发出一个中断。如果我们更关心精确的计时，TICR将使用外部时间源进行校准。
	lapicw(TDCR, X1);
	lapicw(TIMER, PERIODIC | (IRQ_OFFSET + IRQ_TIMER));
	lapicw(TICR, 10000000); 

	// 让BSP的LINT0处于启用状态，这样它就可以从8259A芯片获得中断。
	// 根据Intel MP规范，BIOS应该在虚拟线模式下初始化BSP的本地APIC，其中8259A的INTR实际上连接到BSP的LINTIN0。在这种模式下，我们不需要对IOAPIC进行编程。
	if (thiscpu != bootcpu)
		lapicw(LINT0, MASKED);

	// 在所有cpu上禁用NMI (LINT1)
	lapicw(LINT1, MASKED);

	// 在提供中断项的计算机上禁用性能计数器溢出中断。
	if (((lapic[VER]>>16) & 0xFF) >= 4)
		lapicw(PCINT, MASKED);

	// 将错误中断映射到IRQ_ERROR。
	lapicw(ERROR, IRQ_OFFSET + IRQ_ERROR);

	// 清除错误状态寄存器(需要连续写操作)。
	lapicw(ESR, 0);
	lapicw(ESR, 0);

	// Ack any outstanding interrupts.
	lapicw(EOI, 0);

	// Send an Init Level De-Assert to synchronize arbitration ID's.
	lapicw(ICRHI, 0);
	lapicw(ICRLO, BCAST | INIT | LEVEL);
	while(lapic[ICRLO] & DELIVS)
		;

	// Enable interrupts on the APIC (but not on the processor).
	lapicw(TPR, 0);
}
```

mmio_map_region实现了分配空间并映射设备内存。

在lapic_init的开始，调用了mmio_map_region(lapicaddr, 4096)映射了4k的MMIO区域的物理空间到内存，然后我们实现这个函数，参考boot_map_region：

```c
void *
mmio_map_region(physaddr_t pa, size_t size)
{
	// 从哪里开始下一个区域。最初，这是MMIO区域的开始。因为它是静态的，所以在调用mmio_map_region之间会保留它的值(就像boot_alloc中的nextfree一样)。
	static uintptr_t base = MMIOBASE;

	// 保留从基址开始的虚拟内存大小字节，并将物理页[pa,pa+size]映射到虚拟地址[base,base+size]。因为这是设备内存而不是普通的DRAM，你必须告诉CPU缓存访问这个内存是不安全的。幸运的是，页表为此提供了位;除了PTE_W之外，只需使用PTE_PCD|PTE_PWT (cache-disable和write-through)创建映射
	// 确保将size四舍五入为PGSIZE的倍数，并处理该保留是否会溢出MMIOLIM。
	size_t begin = ROUNDDOWN(pa, PGSIZE), end = ROUNDUP(pa + size, PGSIZE);
    size_t map_size = end - begin;
    if (base + map_size >= MMIOLIM) {
        panic("overflow MMIOLIM");
    }    
    boot_map_region(kern_pgdir, base, map_size, pa, PTE_PCD|PTE_PWT|PTE_W);
    uintptr_t result = base;
    base += map_size;
    return (void *)result;
}
```

我们现在还不能进行测试，要做完下一个练习才行。

###Application Processor Bootstrap

​		在启动APs之前，BSP应该首先收集关于多处理器系统的信息，例如cpu的总数、它们的APIC id和LAPIC单元的MMIO地址。kern/mpconfig.c中的mp_init()函数通过读取驻留在BIOS内存区域中的MP配置表来检索这些信息。

​		boot_aps()函数(在kern/init.c中)驱动AP引导进程。APs以实际模式启动，与boot/boot.S中的bootloader启动方式非常相似。因此，boot_aps()将AP条目代码(kern/mpentry.S)复制到一个在实际模式中可寻址的内存位置。与引导加载程序不同，我们可以控制AP从哪里开始执行代码;我们将条目代码复制到0x7000 (MPENTRY_PADDR)，但是任何未使用的、页面对齐的物理地址低于640KB都可以工作。

​		在此之后，boot_aps()将启动后的IPIs发送到相应AP的LAPIC单元，并将初始CS:IP地址(在我们的示例中，AP应该在这个地址上开始运行其条目代码(MPENTRY_PADDR)，从而逐个激活AP。输入码在kern/mpentry。S与boot/boot.S非常相似。经过一些简单的设置之后，它将AP置于启用分页的保护模式，然后调用C设置例程mp_main()(也在kern/init.c中)。boot_aps()等待AP在其结构CpuInfo的cpu_status字段中发出CPU_STARTED标志的信号，然后继续唤醒下一个标记。

### 练习2

在kern/init中读取boot_aps()和mp_main()。和汇编代码的kern/mpentry.S。确保您了解在APs引导期间的控制流传输。然后在kern/pmap.c中修改page_init()的实现，以避免将MPENTRY_PADDR页面添加到空闲列表中，这样我们就可以安全地复制并运行该物理地址上的AP引导代码。

```
void
page_init(void)
{
	...
	    for (i = 1; i < npages_basemem; i++) {
		if (i == PGNUM(MPENTRY_PADDR)) continue;  //在这里检测MPENTRY_PADDR
        	pages[i].pp_ref = 0;
        	pages[i].pp_link = page_free_list;
        	page_free_list = &pages[i];
    	}
    ...
}
```

后面测试的时候发现昨天在切换lab4分支的时候，并没有将lab3的内容合并过来，所以很多函数该补全的内容都没有，返回分支3发现前面的内容没了，还好昨天把虚拟机快照了一下，恢复快照之后把lab3的内容重新提交，合并的时候提示有冲突（感觉哪里怪怪的），发现多了几个====和<<<<<，我就直接把这几行删了。然后重新提交：

[![Gvr7Of.jpg](https://s1.ax1x.com/2020/04/13/Gvr7Of.jpg)](https://imgchr.com/i/Gvr7Of)

提示有一个崩溃，找一下这一行发现是check_kern_pgdir(void)这个函数的，也就是题目说的那个，所以不管。

（我的微博图床bug找到了，提示错误码-5是因为账号异常，好像是太久不用微博被黑了，sad，申诉中）

###Per-CPU State and Initialization

​		在编写多处理器操作系统时，一定要区分每个处理器私有的cpu状态和整个系统共享的全局状态。 `kern/cpu.h` 定义了per-cpu的大部分状态，包括存储per-cpu变量的struct CpuInfo。cpunum()总是返回调用它的CPU的ID，它可以像CPU一样用作数组的索引。宏thiscpu是当前CPU结构CpuInfo的简写。

每个CPU如下信息是当前CPU私有的：

- 内核堆栈

  因为多个cpu可以同时进入内核，所以我们需要为每个处理器创建一个单独的内核堆栈，以防止它们相互干扰执行。数组percpu_kstacks[NCPU][KSTKSIZE]为NCPU的内核堆栈保留KSTKSIZE大小的空间。

  在实验2中，我们映射了引导堆栈称为BSP的内核堆栈的物理内存，它刚好位于KSTACKTOP之下。类似地，在这个实验中，我们将把每个CPU的内核堆栈映射到这个区域，并使用保护页面作为它们之间的缓冲区。CPU 0的堆栈仍然会从KSTACKTOP向下增长;CPU 1的堆栈将从CPU 0的堆栈底部以下的KSTKGAP字节开始，以此类推。inc/memlayout.h显示映射布局。

- TSS和TSS描述符

  每个CPU都需要单独的TSS和TSS描述符来指定该CPU对应的内核栈。用于CPU i的TSS存储在CPU [i].cpu_ts中，对应的TSS描述符在GDT条目GDT [(GD_TSS0 >> 3) + i]中定义。在kern/trap.c中定义的全局ts变量将不再有用。

- 当前环境指针

  由于每个CPU可以同时运行不同的用户进程，所以我们重新定义了curenv符号来指代CPU [cpunum()].cpu_env(或者thiscpu->cpu_env)，它指向当前CPU(运行代码的CPU)上当前执行的环境。

- 系统寄存器

  所有的寄存器，包括系统寄存器，对CPU都是私有的。因此，初始化这些寄存器的指令，如lcr3()、ltr()、lgdt()、lidt()等，必须在每个CPU上执行一次。为此定义了函数env_init_percpu()和trap_init_percpu()。

### 练习3

修改mem_init_mp()(在kern/pmap.c中)，以映射从KSTACKTOP开始的每个cpu堆栈，如inc/memlayout.h中所示。每个堆栈的大小是KSTKSIZE字节加上未映射保护页的KSTKGAP字节。通过check_kern_pgdir()检查。

```c
static void
mem_init_mp(void)
{
	// 映射每个cpu堆栈，从KSTACKTOP开始，直到“NCPU”cpu。对于CPU i，使用'percpu_kstack [i]'所指的物理内存作为其内核堆栈。CPU i的内核堆栈从虚拟地址kstacktop_i = KSTACKTOP - i * (KSTKSIZE + KSTKGAP)开始向下扩展，并被分成两部分，就像你在mem_init中设置的单一堆栈一样:
	//     * [kstacktop_i - KSTKSIZE, kstacktop_i)
	//          -- 物理内存支持
	//     * [kstacktop_i - (KSTKSIZE + KSTKGAP), kstacktop_i - KSTKSIZE)
	//          -- 不支持;因此，如果内核溢出它的堆栈，它将出错而不是覆盖另一个CPU的堆栈。被称为“保护页面”。
	//     权限:内核RW，用户无
	//
	// LAB 4: Your code here:
	 int i;
    	for (i = 0; i < NCPU; i++) {
        	int kstacktop_i = KSTACKTOP - KSTKSIZE - i * (KSTKSIZE + KSTKGAP);
        	boot_map_region(kern_pgdir, kstacktop_i, KSTKSIZE, PADDR(percpu_kstacks[i]), PTE_W);
    	}
}
```

### 练习4

trap_init_percpu() (kern/trap.c)中的代码初始化BSP的TSS和TSS描述符。它在实验3中工作，但在其他cpu上运行时是不正确的。更改代码，使其可以在所有cpu上工作。(注意:您的新代码不应该再使用全局ts变量。)

```c
void
trap_init_percpu(void)
{
	// 这里的示例代码为CPU 0设置任务状态段(TSS)和TSS描述符。但是，如果我们在其他CPU上运行，这是不正确的，因为每个CPU都有自己的内核堆栈。修复代码，使其适用于所有cpu。
	//
	// Hints:
	//   - 宏“thiscpu”总是指当前CPU的结构CpuInfo;
	//   - 当前CPU的ID由cpunum()或thiscpu- gt;cpu_id给出;
	//   - 使用“thiscpu- gt;cpu_ts”作为当前CPU的TSS，而不是全局“ts”变量;
	//   - 使用gdt[(GD_TSS0 &gt;&gt;3) + i]表示CPU i的TSS描述符;
	//   - 在mem_init_mp()中映射每个cpu内核堆栈
	//   - 初始化cpu_ts。ts_iomb防止未授权的环境执行IO(0不是正确的值!)
	//
	// ltr在TSS选择器中设置了一个'busy'标志，因此如果您不小心将相同的TSS加载到多个CPU上，您将得到一个三重错误。如果您设置了单个CPU的TSS错误，那么在尝试从该CPU上的用户空间返回之前，可能不会出现错误。
	//
	// LAB 4: Your code here:

	// Setup a TSS so that we get the right stack
	// when we trap to the kernel.
	int cpu_id = thiscpu->cpu_id;
    struct Taskstate *this_ts = &thiscpu->cpu_ts;
    this_ts->ts_esp0 = KSTACKTOP - cpu_id * (KSTKSIZE + KSTKGAP);
    this_ts->ts_ss0 = GD_KD;
    this_ts->ts_iomb = sizeof(struct Taskstate);

	// Initialize the TSS slot of the gdt.
	gdt[(GD_TSS0 >> 3) + cpu_id] = SEG16(STS_T32A, (uint32_t) (this_ts),
                    sizeof(struct Taskstate) - 1, 0); 
    gdt[(GD_TSS0 >> 3) + cpu_id].sd_s = 0;

	// Load the TSS selector (like other segment selectors, the
	// bottom three bits are special; we leave them 0)
	ltr(GD_TSS0 + (cpu_id << 3));

	// Load the IDT
	lidt(&idt_pd);
}
```

make qemu CPUS=4一下：

[![JkZdeA.jpg](https://s1.ax1x.com/2020/04/16/JkZdeA.jpg)](https://imgchr.com/i/JkZdeA)

### 锁

​		我们当前的代码在mp_main()中初始化AP之后旋转。在让AP更进一步之前，我们需要首先解决多个cpu同时运行内核代码时的竞争条件。实现这一点的最简单方法是使用big kernel lock。big kernel lock是一个单独的全局锁，它在环境进入内核模式时持有，在环境返回用户模式时释放。在这个模型中，用户模式下的环境可以并发地运行在任何可用的cpu上，但是内核模式下最多只能运行一个环境;任何其他试图进入内核模式的环境都必须等待。

​		kern/spinlock.h声明了big kernel lock，即kernel_lock。它还提供了lock_kernel()和unlock_kernel()，它们是获取和释放锁的快捷方式。

```c
// Mutual exclusion lock.
struct spinlock {
	unsigned locked;       // Is the lock held?

#ifdef DEBUG_SPINLOCK
	// For debugging:
	char *name;            // Name of lock.
	struct CpuInfo *cpu;   // The CPU holding the lock.
	uintptr_t pcs[10];     // The call stack (an array of program counters)
	                       // that locked the lock.
#endif
};
extern struct spinlock kernel_lock;
```

这是一个自旋锁，是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。

```c
static inline void
lock_kernel(void)
{
	spin_lock(&kernel_lock);
}

static inline void
unlock_kernel(void)
{
	spin_unlock(&kernel_lock);

	// Normally we wouldn't need to do this, but QEMU only runs
	// one CPU at a time and has a long time-slice.  Without the
	// pause, this CPU is likely to reacquire the lock before
	// another CPU has even been given a chance to acquire it.
	asm volatile("pause");
}
```

lock_kernel()和unlock_kernel()实际上是使用spin_lock()和spin_unlock()来实现的，下面是这两个函数的具体实现：

```c
void
spin_lock(struct spinlock *lk)
{
#ifdef DEBUG_SPINLOCK
	if (holding(lk))
		panic("CPU %d cannot acquire %s: already holding", cpunum(), lk->name);
#endif

	// xchg是一个原子操作.
	// 它还可以序列化，这样在获取之后的读取不会在它之前重新排序。
	while (xchg(&lk->locked, 1) != 0)
		asm volatile ("pause");

	// 记录用于调试的锁获取信息。
#ifdef DEBUG_SPINLOCK
	lk->cpu = thiscpu;
	get_caller_pcs(lk->pcs);
#endif
}
// Release the lock.
void
spin_unlock(struct spinlock *lk)
{
#ifdef DEBUG_SPINLOCK
	if (!holding(lk)) {
		int i;
		uint32_t pcs[10];
		// 在EIP链被释放之前将其捕获
		memmove(pcs, lk->pcs, sizeof pcs);
		cprintf("CPU %d cannot release %s: held by CPU %d\nAcquired at:", 
			cpunum(), lk->name, lk->cpu->cpu_id);
		for (i = 0; i < 10 && pcs[i]; i++) {
			struct Eipdebuginfo info;
			if (debuginfo_eip(pcs[i], &info) >= 0)
				cprintf("  %08x %s:%d: %.*s+%x\n", pcs[i],
					info.eip_file, info.eip_line,
					info.eip_fn_namelen, info.eip_fn_name,
					pcs[i] - info.eip_fn_addr);
			else
				cprintf("  %08x\n", pcs[i]);
		}
		panic("spin_unlock");
	}

	lk->pcs[0] = 0;
	lk->cpu = 0;
#endif

	// xchg指令相对于引用相同内存的任何其他指令是原子性的(即使用“锁”前缀)。x86 cpu不会跨锁定指令重新排序加载/存储。因为xchg()是使用asm volatile实现的，所以gcc不会跨xchg对C语句重新排序。
	xchg(&lk->locked, 0);
}
```

使用xchgl这个原子指令，xchg()封装了该指令，交换lk->locked和1的值，并将lk-locked原来的值返回。如果lk-locked原来的值不等于0，说明该锁已经被别的CPU申请了。

你应该在四个地方应用锁:

- 在i386_init()中，在BSP唤醒其他cpu之前获取锁。
- 在mp_main()中，在初始化AP之后获取锁，然后调用sched_yield()在该AP上启动运行环境。
- 在trap()中，从用户模式捕获锁。要确定陷阱是在用户模式还是在内核模式下发生的，请检查tf_cs的低位。
- 在env_run()中，在切换到用户模式之前释放锁。不要太早或太晚这样做，否则你将经历种族或死锁。

### 练习5

如前所述，通过在适当的位置调用lock_kernel()和unlock_kernel()来应用内核锁。

第一个在init.c中的i386_init()函数中：

```c
// Acquire the big kernel lock before waking up APs
// Your code here:
lock_kernel();
// Starting non-boot CPUs
boot_aps();
```

第二个在mp_main()中：

```c
// Now that we have finished some basic setup, call sched_yield()
// to start running processes on this CPU.  But make sure that
// only one CPU can enter the scheduler at a time!
//
// Your code here:
lock_kernel();
sched_yield();
// Remove this after you finish Exercise 6
//for (;;);
```

第三个在trap.c中的trap()函数中：

```c
if ((tf->tf_cs & 3) == 3) {
// Trapped from user mode.
// Acquire the big kernel lock before doing any
// serious kernel work.
// LAB 4: Your code here.
lock_kernel();
assert(curenv);
```

最后一个在env.c的env_run()中,在函数的最后：

```c
curenv = e;
curenv->env_status = ENV_RUNNING;
curenv->env_runs++;
lcr3(PADDR(curenv->env_pgdir));
unlock_kernel();
env_pop_tf(&curenv->env_tf);
```

### Round-Robin Scheduling

这个实验的下一个任务是更改JOS内核，以便它能够以“循环”的方式在多个环境之间交替。JOS的循环调度工作如下:

- kern/sched.c中的sched_yield()函数负责选择要运行的新环境。搜索顺序通过env[]数组以循环的方式,刚开始之前运行环境(或数组的开始如果没有之前运行环境),选择第一个环境它发现的地位ENV_RUNNABLE(见 `inc/env.h`),并调用env_run()进入环境。

- sched_yield()绝不能在两个cpu上同时运行相同的环境。它可以判断一个环境当前正在某个CPU(可能是当前CPU)上运行，因为该环境的状态将是ENV_RUNNING。
- 我们为您实现了一个新的系统调用sys_yield()，用户环境可以调用它来调用内核的sched_yield()函数，从而自动地将CPU交给另一个环境。

### 练习6

如上所述，在sched_yield()中实现循环调度。不要忘记修改syscall()来调度sys_yield()。

确保在mp_main中调用sched_yield()。

修改kern/init.c，以创建三个(或更多!)环境，所有环境都运行程序user/ yield.c。

运行make qemu。您应该看到环境在终止之前在彼此之间来回切换了五次，如下所示。

还可以使用多个cpu进行测试:使qemu cpu =2。

```
...
Hello, I am environment 00001000.
Hello, I am environment 00001001.
Hello, I am environment 00001002.
Back in environment 00001000, iteration 0.
Back in environment 00001001, iteration 0.
Back in environment 00001002, iteration 0.
Back in environment 00001000, iteration 1.
Back in environment 00001001, iteration 1.
Back in environment 00001002, iteration 1.
...
```

在yield程序退出后，系统中将没有可运行的环境，调度器应该调用JOS内核监视器。如果这些都没有发生，那么在继续之前修复您的代码。

kern/sched.c中调度函数实现：

```C
void
sched_yield(void)
{
	struct Env *idle;

	// 实现简单的循环调度。
	// 在'envs'中搜索' ENV_RUNNABLE环境'，以循环方式在这个CPU最后一次运行后开始。切换到找到的第一个这样的环境。
	//如果没有envs是可运行的，但是之前在这个CPU上运行的环境仍然是ENV_RUNNING，那么可以选择该环境。
	// 永远不要选择当前在另一个CPU上运行的环境(env_status == ENV_RUNNING)。如果没有可运行的环境，只需通过下面的代码来停止cpu
	// LAB 4: Your code here.
	idle = curenv;
	int start_envid = idle ? ENVX(idle->env_id)+1 : 0;  //从当前Env结构的后一个开始

	for (int i = 0; i < NENV; i++) {   //遍历所有Env结构
		int j = (start_envid + i) % NENV;
		if (envs[j].env_status == ENV_RUNNABLE) {
			env_run(&envs[j]);
		}
	}

	if (idle && idle->env_status == ENV_RUNNING) {   //假设当前只有一个Env，如果没有这个判断，那么这个CPU将会停机
		env_run(idle);
	}
	// sched_halt never returns
	sched_halt();
}
```

修改syscall.c中的syscall（）函数，添加如下代码：

```C
case SYS_yield:
	sys_yield();
	return 0;
```

修改kern/init.c

```c
// Touch all you want.
//ENV_CREATE(user_primes, ENV_TYPE_USER);
ENV_CREATE(user_yield, ENV_TYPE_USER);
ENV_CREATE(user_yield, ENV_TYPE_USER);
ENV_CREATE(user_yield, ENV_TYPE_USER);
```

 make qemu可看到：

[![Jkg0Y9.jpg](https://s1.ax1x.com/2020/04/16/Jkg0Y9.jpg)](https://imgchr.com/i/Jkg0Y9)

切换之后调用了JOS监视器

### System Calls for Environment Creation

​		尽管我们的内核现在能够在多个用户级环境之间运行和切换，但它仍然局限于内核最初设置的运行环境。现在，我们将实现必要的JOS系统调用，以允许用户环境创建和启动其他新用户环境。

​		Unix提供fork()系统调用作为其进程创建原语。Unix fork()复制调用进程(父进程)的整个地址空间，以创建一个新进程(子进程)。来自用户空间的两个可见对象之间的惟一区别是它们的进程id和父进程id(由getpid和getppid返回)。在父进程中，fork()返回子进程的进程ID，而在子进程中，fork()返回0。默认情况下，每个进程都有自己的私有地址空间，两个进程对内存的修改对另一个进程都是不可见的。

​		我们将提供一组不同的、更原始的JOS系统调用，用于创建新的用户模式环境。使用这些系统调用，除了创建其他风格的环境之外，我们还可以完全在用户空间中实现类似unix的fork()。你将为JOS编写的新系统调用如下:

**`sys_exofork`:**

​		这个系统调用创建了一个几乎是空白的新环境:它的地址空间的用户部分没有映射任何东西，并且它是不可运行的。新环境将具有与sys_exofork调用时的父环境相同的寄存器状态。在父类中，sys_exofork将返回新创建环境的envid_t(如果环境分配失败，则返回一个负错误代码)。然而，在子节点中，它将返回0。(由于子进程一开始被标记为不可运行，所以sys_exofork实际上不会在子进程中返回，直到父进程通过使用……标记子进程可运行，从而显式地允许这样做。)

**`sys_env_set_status`:**

​		将指定环境的状态设置为ENV_RUNNABLE或ENV_NOT_RUNNABLE。这个系统调用通常用于在地址空间和寄存器状态完全初始化之后，标记一个准备运行的新环境。

**`sys_page_alloc`:**

​		分配物理内存页，并将其映射到给定环境的地址空间中的给定虚拟地址。

**`sys_page_map`:**

​		将一个页面映射(不是页面的内容!)从一个环境的地址空间复制到另一个环境，保留一个内存共享安排，以便新映射和旧映射都指向物理内存的同一个页面。

**`sys_page_unmap`:**

​		取消映射映射到给定环境中给定虚拟地址的页面。

对于上面所有接受环境id的系统调用，JOS内核支持这样的约定:值0表示“当前环境”。该公约由envid2env()在kern/env.c中实现。

​		我们在测试程序user/dumbfork.c中提供了一个非常原始的类unix fork()实现。这个测试程序使用上面的系统调用来创建和运行带有自己的地址空间副本的子环境。然后，这两个环境使用sys_yield来回切换，与前面的练习一样。父元素在10次迭代后退出，而子元素在20次迭代后退出。

### 练习7

实现上面在kern/syscall.c中描述的系统调用，并确保syscall()调用它们。您将需要使用kern/pmap.c和kern/env.c中的各种函数,尤其是envid2env ()。现在，无论何时调用envid2env()，都要在checkperm参数中传递1。确保检查了所有无效的系统调用参数，在这种情况下返回-E_INVAL。使用user/dumbfork测试您的JOS内核，并确保它在继续之前能够正常工作。

我们要实现上面提到的五个函数

sys_exofork(void)：

```c
static envid_t
sys_exofork(void)
{
	// 使用env_alloc()从kern/env.c创建新环境。它应该保留为创建它时的env_alloc，只是状态设置为ENV_NOT_RUNNABLE，并且寄存器集是从当前环境中复制的——但是进行了调整，使sys_exofork看起来返回0。

	// LAB 4: Your code here.
	struct Env *e; 
    int ret = env_alloc(&e, curenv->env_id);  //分配一个Env结构
    if (ret) return ret;

    e->env_status = ENV_NOT_RUNNABLE;    //目前还不能运行
    e->env_tf = curenv->env_tf;          //寄存器状态和当前进程一致
    e->env_tf.tf_regs.reg_eax = 0;       //新的进程从sys_exofork()的返回值应该为0
    return e->env_id;
	//panic("sys_exofork not implemented");
}
```

sys_env_set_status(envid_t envid, int status):将envid的env_status设置为状态，它必须是ENV_RUNNABLE或ENV_NOT_RUNNABLE。

```c
static int
sys_env_set_status(envid_t envid, int status)
{
	// 提示:使用kern/ Env. c中的'envid2env'函数将一个envid转换成一个结构Env。您应该将envid2env的第三个参数设置为1，它将检查当前环境是否具有设置envid状态的权限。

	// LAB 4: Your code here.
	struct Env *e;
    if (envid2env(envid, &e, 1)) return -E_BAD_ENV;
    
    if (status != ENV_NOT_RUNNABLE && status != ENV_RUNNABLE) return -E_INVAL;
    
    e->env_status = status;
    return 0;
	//panic("sys_env_set_status not implemented");
}
```

sys_page_alloc(envid_t envid, void *va, int perm):在'envid'的地址空间中，使用'perm'权限在'va'上分配一页内存并将其映射到'va'。页面的内容被设置为0。如果一个页面已经在'va'被映射，那么该页面将作为一个副作用被取消映射.必须设置PTE_U | PTE_P, PTE_AVAIL | PTE_W可以设置也可以不设置，

```C
static int
sys_page_alloc(envid_t envid, void *va, int perm)
{
	//提示:这个函数是对kern/pmap.c中的page_alloc()和page_insert()的包装。您编写的大多数新代码都应该检查参数的正确性。如果page_insert()失败，请记住释放所分配的页面

	// LAB 4: Your code here.
	 struct Env *e;   //根据envid找出需要操作的Env结构
    if (envid2env(envid, &e, 1) < 0) return -E_BAD_ENV;

    int valid_perm = (PTE_U|PTE_P);
    if (va >= (void *)UTOP || (perm & valid_perm) != valid_perm) {
        return -E_INVAL;
    }

    struct PageInfo *p = page_alloc(1);   //分配物理页
    if (!p) return -E_NO_MEM;

    int ret = page_insert(e->env_pgdir, p, va, perm);   //建立映射关系
    if (ret) {
        page_free(p);
    }
    return ret;
	//panic("sys_page_alloc not implemented");
}
```

sys_page_map(envid_t srcenvid, void *srcva,envid_t dstenvid, void *dstva, int perm):在dstenvid的地址空间中，在srcenvid的地址空间中，将内存页映射到“srcva”，并允许“perm”。Perm具有与sys_page_alloc相同的限制，但它也不能授予对只读页面的写访问权。

```C
static int
sys_page_map(envid_t srcenvid, void *srcva,
	     envid_t dstenvid, void *dstva, int perm)
{
	//提示:这个函数是对kern/pmap.c中的page_lookup()和page_insert()的包装。同样，您编写的大多数新代码应该检查参数的正确性。使用page_lookup()的第三个参数检查页面上的当前权限。

	// LAB 4: Your code here.
	struct Env *srcenv, *dstenv;
    if (envid2env(srcenvid, &srcenv, 1) || envid2env(dstenvid, &dstenv, 1)) {
        return -E_BAD_ENV;
    }
    //如果srcva >= UTOP或srcva没有页面对齐，或者dstva >= UTOP或者dstva没有页面对齐。
    if (srcva >= (void *)UTOP || dstva >= (void *)UTOP || PGOFF(srcva) || PGOFF(dstva)) {
        return -E_INVAL;
    }
    //-E_INVAL是srcva没有映射到srcenvid的地址空间。
    pte_t *pte;
    struct PageInfo *p = page_lookup(srcenv->env_pgdir, srcva, &pte);
    if (!p) return -E_INVAL;

    int valid_perm = (PTE_U|PTE_P);
    if ((perm&valid_perm) != valid_perm) return -E_INVAL;

    if ((perm & PTE_W) && !(*pte & PTE_W)) return -E_INVAL;

    int ret = page_insert(dstenv->env_pgdir, p, dstva, perm);
    return ret;
	//panic("sys_page_map not implemented");
}
```

sys_page_unmap(envid_t envid, void *va):在'envid'的地址空间中取消'va'处内存页的映射。

```c
static int
sys_page_unmap(envid_t envid, void *va)
{
	// 提示:这个函数是对page_remove()的包装。

	// LAB 4: Your code here.
	struct Env *e;
    if (envid2env(envid, &e, 1)) return -E_BAD_ENV;

    if (va >= (void *)UTOP) return -E_INVAL;

    page_remove(e->env_pgdir, va);
    return 0;
	//panic("sys_page_unmap not implemented");
}
```

然后在syscall()函数中加入对应的系统调用分发代码

```c
case SYS_exofork:
     return sys_exofork();
case SYS_env_set_status:
     return sys_env_set_status(a1, a2);
case SYS_page_alloc:
     return sys_page_alloc(a1, (void *)a2, a3);
case SYS_page_map:
     return sys_page_map(a1, (void*)a2, a3, (void*)a4, a5);
case SYS_page_unmap:
     return sys_page_unmap(a1, (void *)a2);
```

最后修改 kern/init.c 中加载的用户程序为 `user_dumbfork`

`ENV_CREATE(user_dumbfork, ENV_TYPE_USER);`

然后make qemu ：

![屏幕截图.jpg](http://ww1.sinaimg.cn/large/005KQQDely1gdwqf01pjej30dc0ejjsa.jpg)

![屏幕截图.jpg](http://ww1.sinaimg.cn/large/005KQQDely1gdwqfir2u9j30du09r74z.jpg)

子进程和父进程按要求切换，

![屏幕截图.jpg](http://ww1.sinaimg.cn/large/005KQQDely1gdwqgovztrj306k01e0sk.jpg)

partA测试通过。