---
layout:     post   				    # 使用的布局（不需要改）
title:      6828-lab4（4.18更新）		# 标题 
#subtitle:   脚本，xss #副标题
date:       2020-04-12 				# 时间
author:     s-seven 						# 作者
header-img: img/post-bg-2015.jpg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - 6828
---

#Lab 4: Preemptive Multitasking

在这个实验中，我们将在多个同时活动的用户模式环境中实现先发制人的多任务处理。

在第A部分中，我们将向jos添加多处理器支持、实现循环调度并添加基本的环境管理系统调用(创建和破坏环境的调用以及分配/映射内存的调用)。

在第B部分中，我们将实现一个类unix的fork()，它允许用户模式环境创建自身的副本。

最后，在第C部分中，我们将添加对进程间通信(IPC)的支持，允许不同的用户模式环境显式地相互通信和同步。我们还将添加对硬件时钟中断和抢占的支持。

在切换分支时，我遇到了一个问题：

```
s-seven@sseven-virtual-machine:~/lab$ git pull
error: 您尚未结束您的合并（存在 MERGE_HEAD）。
提示：请在合并前先提交您的修改。
fatal: 因为存在未完成的合并而退出。
```

搜索相关问题后输入`rm .git/MERGE_HEAD`解决这个

```
git checkout -b lab4 origin/lab4
error: 您对下列文件的本地修改将被检出操作覆盖：
	kern/env.c
	kern/pmap.c
	kern/syscall.c
	kern/trap.c
	kern/trapentry.S
	lib/printfmt.c
请在切换分支前提交或贮藏您的修改。
终止中
```

原来我这些没有提交，

```
s-seven@sseven-virtual-machine:~/lab$ git stash
保存工作目录和索引状态 WIP on lab3: a9d7717 Lab 3
```

保存一下就好了

悲伤的是，微博图床不能用了。。。

然后发现多了下面的内容：

| `kern/cpu.h`      | Kernel-private definitions for multiprocessor support        |
| ----------------- | ------------------------------------------------------------ |
| `kern/mpconfig.c` | Code to read the multiprocessor configuration                |
| `kern/lapic.c`    | Kernel code driving the local APIC unit in each processor    |
| `kern/mpentry.S`  | Assembly-language entry code for non-boot CPUs               |
| `kern/spinlock.h` | Kernel-private definitions for spin locks, including the big kernel lock |
| `kern/spinlock.c` | Kernel code implementing spin locks                          |
| `kern/sched.c`    | Code skeleton of the scheduler that you are about to implement |

## Part A: 多处理器支持和多任务协作

​		在本实验的第一部分中，我们将首先扩展JOS，使其在多处理器系统上运行，然后实现一些新的JOS内核系统调用，以允许用户级环境创建额外的新环境。我们还将实现协作循环调度，允许内核在当前环境自动放弃CPU(或退出)时从一个环境切换到另一个环境。在C部分的后面部分，您将实现抢占式调度，它允许内核在经过一段时间之后，即使环境不合作，也可以从环境中重新获得对CPU的控制。

### Multiprocessor Support

​		我们将使JOS支持“对称多处理”(SMP)，这是一种多处理器模型，其中所有cpu都可以对系统资源(如内存和I/O总线)进行等效访问。虽然SMP中的所有cpu在功能上都是相同的，但在引导过程中它们可以分为两种类型:引导处理器(bootstrap processor, BSP)负责初始化系统和引导操作系统;只有在操作系统启动并运行之后，BSP才会激活应用程序处理器(APs)。哪个处理器是BSP是由硬件和BIOS决定的。到目前为止，您所有现有的JOS代码都是在BSP上运行的。

​		在SMP系统中，每个CPU都有一个相应的本地APIC (LAPIC)单元。LAPIC单位负责在整个系统中提供中断。LAPIC还为其连接的CPU提供唯一的标识符。在本实验室，我们利用了LAPIC单元的以下基本功能(以kern/ LAPIC .c表示):

- 读取LAPIC标识符(APIC ID)来告诉我们的代码当前在哪个CPU上运行(参见cpunum())。

- 将启动处理器间中断(IPI)从BSP发送到APs以打开其他cpu(参见lapic_startap())。

- 在第C部分中，我们对LAPIC的内置计时器进行编程，以触发时钟中断来支持先发制人的多任务处理(参见apic_init())。

处理器使用内存映射I/O (MMIO)访问它的LAPIC。在MMIO中，物理内存的一部分被硬连接到一些I/O设备的寄存器，因此通常用于访问内存的加载/存储指令也可以用于访问设备寄存器。我们已经看到了物理地址0xA0000处的一个IO漏洞(我们使用它来写入VGA显示缓冲区)。LAPIC位于一个从物理地址0xFE000000开始的洞中(32MB短于4GB)，因此对于我们使用通常的KERNBASE直接映射访问它太高了。JOS虚拟内存映射在MMIOBASE留下了4MB的空白，所以我们有地方来映射这样的设备。由于后来的实验引入了更多的MMIO区域，我们将编写一个简单的函数来从这个区域分配空间并将设备内存映射到它。

### 练习1

在kern/pmap.c中实现mmio_map_region。要了解如何使用它，请查看kern/lapic.c中lapic_init的开头。在运行mmio_map_region测试之前，您还必须进行下一个练习。

所以我们先看一看kern/lapic.c中的lapic_init（）：

```c
void
lapic_init(void)
{
	if (!lapicaddr)
		return;

	// lapicaddr是LAPIC的4K MMIO区域的物理地址。将它映射到虚拟内存中，以便我们可以访问它。
	lapic = mmio_map_region(lapicaddr, 4096);

	// APIC;设置伪中断向量。
	lapicw(SVR, ENABLE | (IRQ_OFFSET + IRQ_SPURIOUS));

	// 定时器从lapic[TICR]开始以总线频率重复地倒数，然后发出一个中断。如果我们更关心精确的计时，TICR将使用外部时间源进行校准。
	lapicw(TDCR, X1);
	lapicw(TIMER, PERIODIC | (IRQ_OFFSET + IRQ_TIMER));
	lapicw(TICR, 10000000); 

	// 让BSP的LINT0处于启用状态，这样它就可以从8259A芯片获得中断。
	// 根据Intel MP规范，BIOS应该在虚拟线模式下初始化BSP的本地APIC，其中8259A的INTR实际上连接到BSP的LINTIN0。在这种模式下，我们不需要对IOAPIC进行编程。
	if (thiscpu != bootcpu)
		lapicw(LINT0, MASKED);

	// 在所有cpu上禁用NMI (LINT1)
	lapicw(LINT1, MASKED);

	// 在提供中断项的计算机上禁用性能计数器溢出中断。
	if (((lapic[VER]>>16) & 0xFF) >= 4)
		lapicw(PCINT, MASKED);

	// 将错误中断映射到IRQ_ERROR。
	lapicw(ERROR, IRQ_OFFSET + IRQ_ERROR);

	// 清除错误状态寄存器(需要连续写操作)。
	lapicw(ESR, 0);
	lapicw(ESR, 0);

	// Ack any outstanding interrupts.
	lapicw(EOI, 0);

	// Send an Init Level De-Assert to synchronize arbitration ID's.
	lapicw(ICRHI, 0);
	lapicw(ICRLO, BCAST | INIT | LEVEL);
	while(lapic[ICRLO] & DELIVS)
		;

	// Enable interrupts on the APIC (but not on the processor).
	lapicw(TPR, 0);
}
```

mmio_map_region实现了分配空间并映射设备内存。

在lapic_init的开始，调用了mmio_map_region(lapicaddr, 4096)映射了4k的MMIO区域的物理空间到内存，然后我们实现这个函数，参考boot_map_region：

```c
void *
mmio_map_region(physaddr_t pa, size_t size)
{
	// 从哪里开始下一个区域。最初，这是MMIO区域的开始。因为它是静态的，所以在调用mmio_map_region之间会保留它的值(就像boot_alloc中的nextfree一样)。
	static uintptr_t base = MMIOBASE;

	// 保留从基址开始的虚拟内存大小字节，并将物理页[pa,pa+size]映射到虚拟地址[base,base+size]。因为这是设备内存而不是普通的DRAM，你必须告诉CPU缓存访问这个内存是不安全的。幸运的是，页表为此提供了位;除了PTE_W之外，只需使用PTE_PCD|PTE_PWT (cache-disable和write-through)创建映射
	// 确保将size四舍五入为PGSIZE的倍数，并处理该保留是否会溢出MMIOLIM。
	size_t begin = ROUNDDOWN(pa, PGSIZE), end = ROUNDUP(pa + size, PGSIZE);
    size_t map_size = end - begin;
    if (base + map_size >= MMIOLIM) {
        panic("overflow MMIOLIM");
    }    
    boot_map_region(kern_pgdir, base, map_size, pa, PTE_PCD|PTE_PWT|PTE_W);
    uintptr_t result = base;
    base += map_size;
    return (void *)result;
}
```

我们现在还不能进行测试，要做完下一个练习才行。

###Application Processor Bootstrap

​		在启动APs之前，BSP应该首先收集关于多处理器系统的信息，例如cpu的总数、它们的APIC id和LAPIC单元的MMIO地址。kern/mpconfig.c中的mp_init()函数通过读取驻留在BIOS内存区域中的MP配置表来检索这些信息。

​		boot_aps()函数(在kern/init.c中)驱动AP引导进程。APs以实际模式启动，与boot/boot.S中的bootloader启动方式非常相似。因此，boot_aps()将AP条目代码(kern/mpentry.S)复制到一个在实际模式中可寻址的内存位置。与引导加载程序不同，我们可以控制AP从哪里开始执行代码;我们将条目代码复制到0x7000 (MPENTRY_PADDR)，但是任何未使用的、页面对齐的物理地址低于640KB都可以工作。

​		在此之后，boot_aps()将启动后的IPIs发送到相应AP的LAPIC单元，并将初始CS:IP地址(在我们的示例中，AP应该在这个地址上开始运行其条目代码(MPENTRY_PADDR)，从而逐个激活AP。输入码在kern/mpentry。S与boot/boot.S非常相似。经过一些简单的设置之后，它将AP置于启用分页的保护模式，然后调用C设置例程mp_main()(也在kern/init.c中)。boot_aps()等待AP在其结构CpuInfo的cpu_status字段中发出CPU_STARTED标志的信号，然后继续唤醒下一个标记。

### 练习2

在kern/init中读取boot_aps()和mp_main()。和汇编代码的kern/mpentry.S。确保您了解在APs引导期间的控制流传输。然后在kern/pmap.c中修改page_init()的实现，以避免将MPENTRY_PADDR页面添加到空闲列表中，这样我们就可以安全地复制并运行该物理地址上的AP引导代码。

```
void
page_init(void)
{
	...
	    for (i = 1; i < npages_basemem; i++) {
		if (i == PGNUM(MPENTRY_PADDR)) continue;  //在这里检测MPENTRY_PADDR
        	pages[i].pp_ref = 0;
        	pages[i].pp_link = page_free_list;
        	page_free_list = &pages[i];
    	}
    ...
}
```

后面测试的时候发现昨天在切换lab4分支的时候，并没有将lab3的内容合并过来，所以很多函数该补全的内容都没有，返回分支3发现前面的内容没了，还好昨天把虚拟机快照了一下，恢复快照之后把lab3的内容重新提交，合并的时候提示有冲突（感觉哪里怪怪的），发现多了几个====和<<<<<，我就直接把这几行删了。然后重新提交：

[![Gvr7Of.jpg](https://s1.ax1x.com/2020/04/13/Gvr7Of.jpg)](https://imgchr.com/i/Gvr7Of)

提示有一个崩溃，找一下这一行发现是check_kern_pgdir(void)这个函数的，也就是题目说的那个，所以不管。

（我的微博图床bug找到了，提示错误码-5是因为账号异常，好像是太久不用微博被黑了，sad，申诉中）

###Per-CPU State and Initialization

​		在编写多处理器操作系统时，一定要区分每个处理器私有的cpu状态和整个系统共享的全局状态。 `kern/cpu.h` 定义了per-cpu的大部分状态，包括存储per-cpu变量的struct CpuInfo。cpunum()总是返回调用它的CPU的ID，它可以像CPU一样用作数组的索引。宏thiscpu是当前CPU结构CpuInfo的简写。

每个CPU如下信息是当前CPU私有的：

- 内核堆栈

  因为多个cpu可以同时进入内核，所以我们需要为每个处理器创建一个单独的内核堆栈，以防止它们相互干扰执行。数组percpu_kstacks[NCPU][KSTKSIZE]为NCPU的内核堆栈保留KSTKSIZE大小的空间。

  在实验2中，我们映射了引导堆栈称为BSP的内核堆栈的物理内存，它刚好位于KSTACKTOP之下。类似地，在这个实验中，我们将把每个CPU的内核堆栈映射到这个区域，并使用保护页面作为它们之间的缓冲区。CPU 0的堆栈仍然会从KSTACKTOP向下增长;CPU 1的堆栈将从CPU 0的堆栈底部以下的KSTKGAP字节开始，以此类推。inc/memlayout.h显示映射布局。

- TSS和TSS描述符

  每个CPU都需要单独的TSS和TSS描述符来指定该CPU对应的内核栈。用于CPU i的TSS存储在CPU [i].cpu_ts中，对应的TSS描述符在GDT条目GDT [(GD_TSS0 >> 3) + i]中定义。在kern/trap.c中定义的全局ts变量将不再有用。

- 当前环境指针

  由于每个CPU可以同时运行不同的用户进程，所以我们重新定义了curenv符号来指代CPU [cpunum()].cpu_env(或者thiscpu->cpu_env)，它指向当前CPU(运行代码的CPU)上当前执行的环境。

- 系统寄存器

  所有的寄存器，包括系统寄存器，对CPU都是私有的。因此，初始化这些寄存器的指令，如lcr3()、ltr()、lgdt()、lidt()等，必须在每个CPU上执行一次。为此定义了函数env_init_percpu()和trap_init_percpu()。

### 练习3

修改mem_init_mp()(在kern/pmap.c中)，以映射从KSTACKTOP开始的每个cpu堆栈，如inc/memlayout.h中所示。每个堆栈的大小是KSTKSIZE字节加上未映射保护页的KSTKGAP字节。通过check_kern_pgdir()检查。

```c
static void
mem_init_mp(void)
{
	// 映射每个cpu堆栈，从KSTACKTOP开始，直到“NCPU”cpu。对于CPU i，使用'percpu_kstack [i]'所指的物理内存作为其内核堆栈。CPU i的内核堆栈从虚拟地址kstacktop_i = KSTACKTOP - i * (KSTKSIZE + KSTKGAP)开始向下扩展，并被分成两部分，就像你在mem_init中设置的单一堆栈一样:
	//     * [kstacktop_i - KSTKSIZE, kstacktop_i)
	//          -- 物理内存支持
	//     * [kstacktop_i - (KSTKSIZE + KSTKGAP), kstacktop_i - KSTKSIZE)
	//          -- 不支持;因此，如果内核溢出它的堆栈，它将出错而不是覆盖另一个CPU的堆栈。被称为“保护页面”。
	//     权限:内核RW，用户无
	//
	// LAB 4: Your code here:
	 int i;
    	for (i = 0; i < NCPU; i++) {
        	int kstacktop_i = KSTACKTOP - KSTKSIZE - i * (KSTKSIZE + KSTKGAP);
        	boot_map_region(kern_pgdir, kstacktop_i, KSTKSIZE, PADDR(percpu_kstacks[i]), PTE_W);
    	}
}
```

### 练习4

trap_init_percpu() (kern/trap.c)中的代码初始化BSP的TSS和TSS描述符。它在实验3中工作，但在其他cpu上运行时是不正确的。更改代码，使其可以在所有cpu上工作。(注意:您的新代码不应该再使用全局ts变量。)

```c
void
trap_init_percpu(void)
{
	// 这里的示例代码为CPU 0设置任务状态段(TSS)和TSS描述符。但是，如果我们在其他CPU上运行，这是不正确的，因为每个CPU都有自己的内核堆栈。修复代码，使其适用于所有cpu。
	//
	// Hints:
	//   - 宏“thiscpu”总是指当前CPU的结构CpuInfo;
	//   - 当前CPU的ID由cpunum()或thiscpu- gt;cpu_id给出;
	//   - 使用“thiscpu- gt;cpu_ts”作为当前CPU的TSS，而不是全局“ts”变量;
	//   - 使用gdt[(GD_TSS0 &gt;&gt;3) + i]表示CPU i的TSS描述符;
	//   - 在mem_init_mp()中映射每个cpu内核堆栈
	//   - 初始化cpu_ts。ts_iomb防止未授权的环境执行IO(0不是正确的值!)
	//
	// ltr在TSS选择器中设置了一个'busy'标志，因此如果您不小心将相同的TSS加载到多个CPU上，您将得到一个三重错误。如果您设置了单个CPU的TSS错误，那么在尝试从该CPU上的用户空间返回之前，可能不会出现错误。
	//
	// LAB 4: Your code here:

	// Setup a TSS so that we get the right stack
	// when we trap to the kernel.
	int cpu_id = thiscpu->cpu_id;
    struct Taskstate *this_ts = &thiscpu->cpu_ts;
    this_ts->ts_esp0 = KSTACKTOP - cpu_id * (KSTKSIZE + KSTKGAP);
    this_ts->ts_ss0 = GD_KD;
    this_ts->ts_iomb = sizeof(struct Taskstate);

	// Initialize the TSS slot of the gdt.
	gdt[(GD_TSS0 >> 3) + cpu_id] = SEG16(STS_T32A, (uint32_t) (this_ts),
                    sizeof(struct Taskstate) - 1, 0); 
    gdt[(GD_TSS0 >> 3) + cpu_id].sd_s = 0;

	// Load the TSS selector (like other segment selectors, the
	// bottom three bits are special; we leave them 0)
	ltr(GD_TSS0 + (cpu_id << 3));

	// Load the IDT
	lidt(&idt_pd);
}
```

make qemu CPUS=4一下：

[![JkZdeA.jpg](https://s1.ax1x.com/2020/04/16/JkZdeA.jpg)](https://imgchr.com/i/JkZdeA)

### 锁

​		我们当前的代码在mp_main()中初始化AP之后旋转。在让AP更进一步之前，我们需要首先解决多个cpu同时运行内核代码时的竞争条件。实现这一点的最简单方法是使用big kernel lock。big kernel lock是一个单独的全局锁，它在环境进入内核模式时持有，在环境返回用户模式时释放。在这个模型中，用户模式下的环境可以并发地运行在任何可用的cpu上，但是内核模式下最多只能运行一个环境;任何其他试图进入内核模式的环境都必须等待。

​		kern/spinlock.h声明了big kernel lock，即kernel_lock。它还提供了lock_kernel()和unlock_kernel()，它们是获取和释放锁的快捷方式。

```c
// Mutual exclusion lock.
struct spinlock {
	unsigned locked;       // Is the lock held?

#ifdef DEBUG_SPINLOCK
	// For debugging:
	char *name;            // Name of lock.
	struct CpuInfo *cpu;   // The CPU holding the lock.
	uintptr_t pcs[10];     // The call stack (an array of program counters)
	                       // that locked the lock.
#endif
};
extern struct spinlock kernel_lock;
```

这是一个自旋锁，是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。

```c
static inline void
lock_kernel(void)
{
	spin_lock(&kernel_lock);
}

static inline void
unlock_kernel(void)
{
	spin_unlock(&kernel_lock);

	// Normally we wouldn't need to do this, but QEMU only runs
	// one CPU at a time and has a long time-slice.  Without the
	// pause, this CPU is likely to reacquire the lock before
	// another CPU has even been given a chance to acquire it.
	asm volatile("pause");
}
```

lock_kernel()和unlock_kernel()实际上是使用spin_lock()和spin_unlock()来实现的，下面是这两个函数的具体实现：

```c
void
spin_lock(struct spinlock *lk)
{
#ifdef DEBUG_SPINLOCK
	if (holding(lk))
		panic("CPU %d cannot acquire %s: already holding", cpunum(), lk->name);
#endif

	// xchg是一个原子操作.
	// 它还可以序列化，这样在获取之后的读取不会在它之前重新排序。
	while (xchg(&lk->locked, 1) != 0)
		asm volatile ("pause");

	// 记录用于调试的锁获取信息。
#ifdef DEBUG_SPINLOCK
	lk->cpu = thiscpu;
	get_caller_pcs(lk->pcs);
#endif
}
// Release the lock.
void
spin_unlock(struct spinlock *lk)
{
#ifdef DEBUG_SPINLOCK
	if (!holding(lk)) {
		int i;
		uint32_t pcs[10];
		// 在EIP链被释放之前将其捕获
		memmove(pcs, lk->pcs, sizeof pcs);
		cprintf("CPU %d cannot release %s: held by CPU %d\nAcquired at:", 
			cpunum(), lk->name, lk->cpu->cpu_id);
		for (i = 0; i < 10 && pcs[i]; i++) {
			struct Eipdebuginfo info;
			if (debuginfo_eip(pcs[i], &info) >= 0)
				cprintf("  %08x %s:%d: %.*s+%x\n", pcs[i],
					info.eip_file, info.eip_line,
					info.eip_fn_namelen, info.eip_fn_name,
					pcs[i] - info.eip_fn_addr);
			else
				cprintf("  %08x\n", pcs[i]);
		}
		panic("spin_unlock");
	}

	lk->pcs[0] = 0;
	lk->cpu = 0;
#endif

	// xchg指令相对于引用相同内存的任何其他指令是原子性的(即使用“锁”前缀)。x86 cpu不会跨锁定指令重新排序加载/存储。因为xchg()是使用asm volatile实现的，所以gcc不会跨xchg对C语句重新排序。
	xchg(&lk->locked, 0);
}
```

使用xchgl这个原子指令，xchg()封装了该指令，交换lk->locked和1的值，并将lk-locked原来的值返回。如果lk-locked原来的值不等于0，说明该锁已经被别的CPU申请了。

你应该在四个地方应用锁:

- 在i386_init()中，在BSP唤醒其他cpu之前获取锁。
- 在mp_main()中，在初始化AP之后获取锁，然后调用sched_yield()在该AP上启动运行环境。
- 在trap()中，从用户模式捕获锁。要确定陷阱是在用户模式还是在内核模式下发生的，请检查tf_cs的低位。
- 在env_run()中，在切换到用户模式之前释放锁。不要太早或太晚这样做，否则你将经历种族或死锁。

### 练习5

如前所述，通过在适当的位置调用lock_kernel()和unlock_kernel()来应用内核锁。

第一个在init.c中的i386_init()函数中：

```c
// Acquire the big kernel lock before waking up APs
// Your code here:
lock_kernel();
// Starting non-boot CPUs
boot_aps();
```

第二个在mp_main()中：

```c
// Now that we have finished some basic setup, call sched_yield()
// to start running processes on this CPU.  But make sure that
// only one CPU can enter the scheduler at a time!
//
// Your code here:
lock_kernel();
sched_yield();
// Remove this after you finish Exercise 6
//for (;;);
```

第三个在trap.c中的trap()函数中：

```c
if ((tf->tf_cs & 3) == 3) {
// Trapped from user mode.
// Acquire the big kernel lock before doing any
// serious kernel work.
// LAB 4: Your code here.
lock_kernel();
assert(curenv);
```

最后一个在env.c的env_run()中,在函数的最后：

```c
curenv = e;
curenv->env_status = ENV_RUNNING;
curenv->env_runs++;
lcr3(PADDR(curenv->env_pgdir));
unlock_kernel();
env_pop_tf(&curenv->env_tf);
```

### Round-Robin Scheduling

这个实验的下一个任务是更改JOS内核，以便它能够以“循环”的方式在多个环境之间交替。JOS的循环调度工作如下:

- kern/sched.c中的sched_yield()函数负责选择要运行的新环境。搜索顺序通过env[]数组以循环的方式,刚开始之前运行环境(或数组的开始如果没有之前运行环境),选择第一个环境它发现的地位ENV_RUNNABLE(见 `inc/env.h`),并调用env_run()进入环境。

- sched_yield()绝不能在两个cpu上同时运行相同的环境。它可以判断一个环境当前正在某个CPU(可能是当前CPU)上运行，因为该环境的状态将是ENV_RUNNING。
- 我们为您实现了一个新的系统调用sys_yield()，用户环境可以调用它来调用内核的sched_yield()函数，从而自动地将CPU交给另一个环境。

### 练习6

如上所述，在sched_yield()中实现循环调度。不要忘记修改syscall()来调度sys_yield()。

确保在mp_main中调用sched_yield()。

修改kern/init.c，以创建三个(或更多!)环境，所有环境都运行程序user/ yield.c。

运行make qemu。您应该看到环境在终止之前在彼此之间来回切换了五次，如下所示。

还可以使用多个cpu进行测试:使qemu cpu =2。

```
...
Hello, I am environment 00001000.
Hello, I am environment 00001001.
Hello, I am environment 00001002.
Back in environment 00001000, iteration 0.
Back in environment 00001001, iteration 0.
Back in environment 00001002, iteration 0.
Back in environment 00001000, iteration 1.
Back in environment 00001001, iteration 1.
Back in environment 00001002, iteration 1.
...
```

在yield程序退出后，系统中将没有可运行的环境，调度器应该调用JOS内核监视器。如果这些都没有发生，那么在继续之前修复您的代码。

kern/sched.c中调度函数实现：

```C
void
sched_yield(void)
{
	struct Env *idle;

	// 实现简单的循环调度。
	// 在'envs'中搜索' ENV_RUNNABLE环境'，以循环方式在这个CPU最后一次运行后开始。切换到找到的第一个这样的环境。
	//如果没有envs是可运行的，但是之前在这个CPU上运行的环境仍然是ENV_RUNNING，那么可以选择该环境。
	// 永远不要选择当前在另一个CPU上运行的环境(env_status == ENV_RUNNING)。如果没有可运行的环境，只需通过下面的代码来停止cpu
	// LAB 4: Your code here.
	idle = curenv;
	int start_envid = idle ? ENVX(idle->env_id)+1 : 0;  //从当前Env结构的后一个开始

	for (int i = 0; i < NENV; i++) {   //遍历所有Env结构
		int j = (start_envid + i) % NENV;
		if (envs[j].env_status == ENV_RUNNABLE) {
			env_run(&envs[j]);
		}
	}

	if (idle && idle->env_status == ENV_RUNNING) {   //假设当前只有一个Env，如果没有这个判断，那么这个CPU将会停机
		env_run(idle);
	}
	// sched_halt never returns
	sched_halt();
}
```

修改syscall.c中的syscall（）函数，添加如下代码：

```C
case SYS_yield:
	sys_yield();
	return 0;
```

修改kern/init.c

```c
// Touch all you want.
//ENV_CREATE(user_primes, ENV_TYPE_USER);
ENV_CREATE(user_yield, ENV_TYPE_USER);
ENV_CREATE(user_yield, ENV_TYPE_USER);
ENV_CREATE(user_yield, ENV_TYPE_USER);
```

 make qemu可看到：

[![Jkg0Y9.jpg](https://s1.ax1x.com/2020/04/16/Jkg0Y9.jpg)](https://imgchr.com/i/Jkg0Y9)

切换之后调用了JOS监视器

### System Calls for Environment Creation

​		尽管我们的内核现在能够在多个用户级环境之间运行和切换，但它仍然局限于内核最初设置的运行环境。现在，我们将实现必要的JOS系统调用，以允许用户环境创建和启动其他新用户环境。

​		Unix提供fork()系统调用作为其进程创建原语。Unix fork()复制调用进程(父进程)的整个地址空间，以创建一个新进程(子进程)。来自用户空间的两个可见对象之间的惟一区别是它们的进程id和父进程id(由getpid和getppid返回)。在父进程中，fork()返回子进程的进程ID，而在子进程中，fork()返回0。默认情况下，每个进程都有自己的私有地址空间，两个进程对内存的修改对另一个进程都是不可见的。

​		我们将提供一组不同的、更原始的JOS系统调用，用于创建新的用户模式环境。使用这些系统调用，除了创建其他风格的环境之外，我们还可以完全在用户空间中实现类似unix的fork()。你将为JOS编写的新系统调用如下:

**`sys_exofork`:**

​		这个系统调用创建了一个几乎是空白的新环境:它的地址空间的用户部分没有映射任何东西，并且它是不可运行的。新环境将具有与sys_exofork调用时的父环境相同的寄存器状态。在父类中，sys_exofork将返回新创建环境的envid_t(如果环境分配失败，则返回一个负错误代码)。然而，在子节点中，它将返回0。(由于子进程一开始被标记为不可运行，所以sys_exofork实际上不会在子进程中返回，直到父进程通过使用……标记子进程可运行，从而显式地允许这样做。)

**`sys_env_set_status`:**

​		将指定环境的状态设置为ENV_RUNNABLE或ENV_NOT_RUNNABLE。这个系统调用通常用于在地址空间和寄存器状态完全初始化之后，标记一个准备运行的新环境。

**`sys_page_alloc`:**

​		分配物理内存页，并将其映射到给定环境的地址空间中的给定虚拟地址。

**`sys_page_map`:**

​		将一个页面映射(不是页面的内容!)从一个环境的地址空间复制到另一个环境，保留一个内存共享安排，以便新映射和旧映射都指向物理内存的同一个页面。

**`sys_page_unmap`:**

​		取消映射映射到给定环境中给定虚拟地址的页面。

对于上面所有接受环境id的系统调用，JOS内核支持这样的约定:值0表示“当前环境”。该公约由envid2env()在kern/env.c中实现。

​		我们在测试程序user/dumbfork.c中提供了一个非常原始的类unix fork()实现。这个测试程序使用上面的系统调用来创建和运行带有自己的地址空间副本的子环境。然后，这两个环境使用sys_yield来回切换，与前面的练习一样。父元素在10次迭代后退出，而子元素在20次迭代后退出。

### 练习7

实现上面在kern/syscall.c中描述的系统调用，并确保syscall()调用它们。您将需要使用kern/pmap.c和kern/env.c中的各种函数,尤其是envid2env ()。现在，无论何时调用envid2env()，都要在checkperm参数中传递1。确保检查了所有无效的系统调用参数，在这种情况下返回-E_INVAL。使用user/dumbfork测试您的JOS内核，并确保它在继续之前能够正常工作。

我们要实现上面提到的五个函数

sys_exofork(void)：

```c
static envid_t
sys_exofork(void)
{
	// 使用env_alloc()从kern/env.c创建新环境。它应该保留为创建它时的env_alloc，只是状态设置为ENV_NOT_RUNNABLE，并且寄存器集是从当前环境中复制的——但是进行了调整，使sys_exofork看起来返回0。

	// LAB 4: Your code here.
	struct Env *e; 
    int ret = env_alloc(&e, curenv->env_id);  //分配一个Env结构
    if (ret) return ret;

    e->env_status = ENV_NOT_RUNNABLE;    //目前还不能运行
    e->env_tf = curenv->env_tf;          //寄存器状态和当前进程一致
    e->env_tf.tf_regs.reg_eax = 0;       //新的进程从sys_exofork()的返回值应该为0
    return e->env_id;
	//panic("sys_exofork not implemented");
}
```

sys_env_set_status(envid_t envid, int status):将envid的env_status设置为状态，它必须是ENV_RUNNABLE或ENV_NOT_RUNNABLE。

```c
static int
sys_env_set_status(envid_t envid, int status)
{
	// 提示:使用kern/ Env. c中的'envid2env'函数将一个envid转换成一个结构Env。您应该将envid2env的第三个参数设置为1，它将检查当前环境是否具有设置envid状态的权限。

	// LAB 4: Your code here.
	struct Env *e;
    if (envid2env(envid, &e, 1)) return -E_BAD_ENV;
    
    if (status != ENV_NOT_RUNNABLE && status != ENV_RUNNABLE) return -E_INVAL;
    
    e->env_status = status;
    return 0;
	//panic("sys_env_set_status not implemented");
}
```

sys_page_alloc(envid_t envid, void *va, int perm):在'envid'的地址空间中，使用'perm'权限在'va'上分配一页内存并将其映射到'va'。页面的内容被设置为0。如果一个页面已经在'va'被映射，那么该页面将作为一个副作用被取消映射.必须设置PTE_U | PTE_P, PTE_AVAIL | PTE_W可以设置也可以不设置，

```C
static int
sys_page_alloc(envid_t envid, void *va, int perm)
{
	//提示:这个函数是对kern/pmap.c中的page_alloc()和page_insert()的包装。您编写的大多数新代码都应该检查参数的正确性。如果page_insert()失败，请记住释放所分配的页面

	// LAB 4: Your code here.
	 struct Env *e;   //根据envid找出需要操作的Env结构
    if (envid2env(envid, &e, 1) < 0) return -E_BAD_ENV;

    int valid_perm = (PTE_U|PTE_P);
    if (va >= (void *)UTOP || (perm & valid_perm) != valid_perm) {
        return -E_INVAL;
    }

    struct PageInfo *p = page_alloc(1);   //分配物理页
    if (!p) return -E_NO_MEM;

    int ret = page_insert(e->env_pgdir, p, va, perm);   //建立映射关系
    if (ret) {
        page_free(p);
    }
    return ret;
	//panic("sys_page_alloc not implemented");
}
```

sys_page_map(envid_t srcenvid, void *srcva,envid_t dstenvid, void *dstva, int perm):在dstenvid的地址空间中，在srcenvid的地址空间中，将内存页映射到“srcva”，并允许“perm”。Perm具有与sys_page_alloc相同的限制，但它也不能授予对只读页面的写访问权。

```C
static int
sys_page_map(envid_t srcenvid, void *srcva,
	     envid_t dstenvid, void *dstva, int perm)
{
	//提示:这个函数是对kern/pmap.c中的page_lookup()和page_insert()的包装。同样，您编写的大多数新代码应该检查参数的正确性。使用page_lookup()的第三个参数检查页面上的当前权限。

	// LAB 4: Your code here.
	struct Env *srcenv, *dstenv;
    if (envid2env(srcenvid, &srcenv, 1) || envid2env(dstenvid, &dstenv, 1)) {
        return -E_BAD_ENV;
    }
    //如果srcva >= UTOP或srcva没有页面对齐，或者dstva >= UTOP或者dstva没有页面对齐。
    if (srcva >= (void *)UTOP || dstva >= (void *)UTOP || PGOFF(srcva) || PGOFF(dstva)) {
        return -E_INVAL;
    }
    //-E_INVAL是srcva没有映射到srcenvid的地址空间。
    pte_t *pte;
    struct PageInfo *p = page_lookup(srcenv->env_pgdir, srcva, &pte);
    if (!p) return -E_INVAL;

    int valid_perm = (PTE_U|PTE_P);
    if ((perm&valid_perm) != valid_perm) return -E_INVAL;

    if ((perm & PTE_W) && !(*pte & PTE_W)) return -E_INVAL;

    int ret = page_insert(dstenv->env_pgdir, p, dstva, perm);
    return ret;
	//panic("sys_page_map not implemented");
}
```

sys_page_unmap(envid_t envid, void *va):在'envid'的地址空间中取消'va'处内存页的映射。

```c
static int
sys_page_unmap(envid_t envid, void *va)
{
	// 提示:这个函数是对page_remove()的包装。

	// LAB 4: Your code here.
	struct Env *e;
    if (envid2env(envid, &e, 1)) return -E_BAD_ENV;

    if (va >= (void *)UTOP) return -E_INVAL;

    page_remove(e->env_pgdir, va);
    return 0;
	//panic("sys_page_unmap not implemented");
}
```

然后在syscall()函数中加入对应的系统调用分发代码

```c
case SYS_exofork:
     return sys_exofork();
case SYS_env_set_status:
     return sys_env_set_status(a1, a2);
case SYS_page_alloc:
     return sys_page_alloc(a1, (void *)a2, a3);
case SYS_page_map:
     return sys_page_map(a1, (void*)a2, a3, (void*)a4, a5);
case SYS_page_unmap:
     return sys_page_unmap(a1, (void *)a2);
```

最后修改 kern/init.c 中加载的用户程序为 `user_dumbfork`

`ENV_CREATE(user_dumbfork, ENV_TYPE_USER);`

然后make qemu ：

![屏幕截图.jpg](http://ww1.sinaimg.cn/large/005KQQDely1gdwqf01pjej30dc0ejjsa.jpg)

![屏幕截图.jpg](http://ww1.sinaimg.cn/large/005KQQDely1gdwqfir2u9j30du09r74z.jpg)

子进程和父进程按要求切换，

![屏幕截图.jpg](http://ww1.sinaimg.cn/large/005KQQDely1gdwqgovztrj306k01e0sk.jpg)

partA测试通过。

## Part B: Copy-on-Write Fork

​		如前所述，Unix提供fork()系统调用作为其主要的进程创建原语。fork()系统调用复制调用进程(父进程)的地址空间，以创建一个新进程(子进程)。

​		xv6 Unix通过将父页面中的所有数据复制到分配给子页面的新页面来实现fork()。这与dumbfork()所采用的方法本质上是相同的。将父地址空间复制到子地址空间是fork()操作中最昂贵的部分。

​		但是，在调用fork()之后，通常会立即调用子进程中的exec()，这将用新程序替换子进程的内存。例如，这就是shell通常所做的。在这种情况下，复制父进程的地址空间所花费的时间很大程度上是浪费的，因为子进程在调用exec()之前只会使用很少的内存。

​		出于这个原因，Unix的后续版本利用虚拟内存硬件允许父进程和子进程共享映射到各自地址空间的内存，直到其中一个进程实际修改它。这种技术称为“写时拷贝”。为此，在fork()上，内核将把地址空间映射从父节点复制到子节点，而不是将映射页面的内容复制到子节点，同时将现在共享的页面标记为只读。当两个进程中的一个试图写入其中一个共享页面时，该进程将接受一个页面错误。此时，Unix内核意识到这个页面实际上是一个“虚拟的”或“写时复制”副本，因此它为故障处理过程创建了一个新的、私有的、可写的页面副本。通过这种方式，在实际写入之前，不会实际复制各个页面的内容。这样的优化使得fork()和exec()在子进程中更便宜:子进程在调用exec()之前可能只需要复制一个页面(当前栈的页面)。

​		在本实验的下一部分中，您将实现一个“适当的”类unix fork()，并使用写时复制，作为用户空间库例程。在用户空间中实现fork()和copy-on-write支持的好处是，内核仍然更简单，因此更有可能是正确的。它还允许各个用户模式程序为fork()定义它们自己的语义。需要稍微不同的实现的程序(例如，像dumbfork()这样昂贵的总是复制的版本，或者父进程和子进程在其中共享内存的版本)可以轻松地提供自己的实现。

### COW写时拷贝技术

​		在Linux程序中，fork（）会产生一个和父进程完全相同的子进程，但子进程在此后多会exec系统调用，出于效率考虑，linux中引入了“写时复制“技术，也就是只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程。

​		在fork之后exec之前两个进程用的是相同的物理空间（内存区），子进程的代码段、数据段、堆栈都是指向父进程的物理空间，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。当父子进程中有更改相应段的行为发生时，再为子进程相应的段分配物理空间，如果不是因为exec，内核会给子进程的数据段、堆栈段分配相应的物理空间（至此两者有各自的进程空间，互不影响），而代码段继续共享父进程的物理空间（两者的代码完全相同）。而如果是因为exec，由于两者执行的代码不同，子进程的代码段也会分配单独的物理空间。      

一个栗子：

​		现在有一个父进程P1，这是一个主体，那么它是有灵魂也就身体的。现在在其虚拟地址空间（有相应的数据结构表示）上有：正文段，数据段，堆，栈这四个部分，相应的，内核要为这四个部分分配各自的物理块。即：正文段块，数据段块，堆块，栈块。

1. 现在P1用fork()函数为进程创建一个子进程P2，

内核：

（1）复制P1的正文段，数据段，堆，栈这四个部分，注意是其内容相同。

（2）为这四个部分分配物理块，P2的：正文段－＞PI的正文段的物理块，其实就是不为P2分配正文段块，让P2的正文段指向P1的正文段块，数据段－＞P2自己的数据段块（为其分配对应的块），堆－＞P2自己的堆块，栈－＞P2自己的栈块。如下图所示：同左到右大的方向箭头表示复制内容。

![img](https://pic002.cnblogs.com/images/2012/426620/2012072019525880.jpg)

2. 写时复制技术：内核只为新生成的子进程创建虚拟空间结构，它们来复制于父进程的虚拟究竟结构，但是不为这些段分配物理内存，它们共享父进程的物理空间，当父子进程中有更改相应段的行为发生时，再为子进程相应的段分配物理空间。

![img](https://pic002.cnblogs.com/images/2012/426620/2012072020252592.jpg)

​		 传统的fork()系统调用直接把所有的资源复制给新创建的进程。这种实现过于简单并且效率低下，因为它拷贝的数据也许并不共享，更糟的情况是，如果新进程打算立即执行一个新的映像，那么所有的拷贝都将前功尽弃。Linux的fork()使用写时拷贝（copy-on-write）页实现。写时拷贝是一种可以推迟甚至免除拷贝数据的技术。内核此时并不复制整个进程地址空间，而是让父进程和子进程共享同一个拷贝。只有在需要写入的时候，数据才会被复制，从而使各个进程拥有各自的拷贝。也就是说，资源的复制只有在需要写入的时候才进行，在此之前，只是以只读方式共享。这种技术使地址空间上的页的拷贝被推迟到实际发生写入的时候。在页根本不会被写入的情况下—举例来说，fork()后立即调用exec()—它们就无需复制了。fork()的实际开销就是复制父进程的页表以及给子进程创建惟一的进程描述符。在一般情况下，进程创建后都会马上运行一个可执行的文件，这种优化可以避免拷贝大量根本就不会被使用的数据（地址空间里常常包含数十兆的数据）。

###用户级页面错误处理

​		用户级的写时复制fork()需要知道受写保护的页面上的页面错误，所以这是我们首先要实现的。写时拷贝只是用户级页面错误处理的众多可能用途之一。

​		通常设置一个地址空间，以便页面错误指示何时需要执行某些操作。例如，大多数Unix内核最初只映射新进程堆栈区域中的一个页面，然后“按需”分配和映射其他堆栈页面，因为进程的堆栈消耗增加，并导致尚未映射的堆栈地址上的页面错误。典型的Unix内核必须跟踪在进程空间的每个区域发生页面错误时应该采取什么操作。例如，堆栈区域中的错误通常会分配和映射物理内存的新页。程序的BSS区域中的一个错误通常会分配一个新页面，用0填充它并映射它。在具有需要分页的可执行程序的系统中，文本区域中的错误将从磁盘读取二进制文件的相应页面，然后将其映射。

​		这是内核需要跟踪的大量信息。我们将决定如何处理用户空间中的每个页面错误，而不是采用传统的Unix方法，因为错误对用户空间的损害较小。这种设计的额外好处是允许程序在定义其内存区域时具有极大的灵活性;稍后，我们将使用用户级的页面错误处理来映射和访问基于磁盘的文件系统上的文件。

### 设置页面错误处理程序

​		为了处理自己的页面错误，用户环境需要向JOS内核注册一个页面错误处理程序入口点。用户环境通过新的sys_env_set_pgfault_upcall系统调用注册其页面错误入口点。我们已经向Env结构添加了一个新成员env_pgfault_upcall来记录此信息。

### 练习8

实现sys_env_set_pgfault_upcall系统调用。在查找目标环境的环境ID时，请确保启用权限检查，因为这是一个“危险的”系统调用。

```c
// 通过修改相应的struct Env的'env_pgfault_upcall'字段来设置'envid'的页面错误向上调用。当'envid'导致一个页面错误时，内核将把一个错误记录推到异常堆栈上，然后转移到'func'。
static int
sys_env_set_pgfault_upcall(envid_t envid, void *func)
{
	// LAB 4: Your code here.
	 struct Env *e; 
    	if (envid2env(envid, &e, 1)) return -E_BAD_ENV;
    	e->env_pgfault_upcall = func;
    	return 0;
	//panic("sys_env_set_pgfault_upcall not implemented");
}
```

### 用户环境中的正常堆栈和异常堆栈

​		在正常执行期间，JOS中的一个用户环境将在正常的用户堆栈上运行:它的ESP寄存器开始指向USTACKTOP，它推送的堆栈数据驻留在USTACKTOP- pgsize和USTACKTOP-1(包括USTACKTOP-1)之间的页面上。但是，当在用户模式下发生页面错误时，内核将重新启动用户环境，在另一个堆栈上运行指定的用户级页面错误处理程序，即用户异常堆栈。本质上，我们将使JOS内核代表用户环境实现自动的“堆栈切换”，这与x86处理器在从用户模式转换到内核模式时代表JOS实现堆栈切换的方式非常相似.

​		JOS用户异常堆栈的大小也是一个页面，其顶部被定义为虚拟地址UXSTACKTOP，因此用户异常堆栈的有效字节是从UXSTACKTOP- pgsize到UXSTACKTOP-1(包括UXSTACKTOP-1)。在这个异常堆栈上运行时，用户级的页面错误处理程序可以使用JOS的常规系统调用来映射新页面或调整映射，从而修复最初导致页面错误的任何问题。然后，用户级页面错误处理程序通过汇编语言存根返回原始堆栈上的错误代码。

​		希望支持用户级页面错误处理的每个用户环境都需要为自己的异常堆栈分配内存，使用第A部分中介绍的sys_page_alloc()系统调用。

###调用用户页面错误处理程序

​		我们现在需要更改kern/trap.c中的页面错误处理代码，以处理来自用户模式的页面错误，如下所示。在发生故障时，我们将用户环境的状态称为trap-time状态。

​		如果没有注册页面错误处理程序，则JOS内核将像以前一样使用消息破坏用户环境。否则，内核会在异常堆栈上设置一个trap帧，它看起来就像inc/trap.h中的一个struct UTrapframe:

```
                    <-- UXSTACKTOP
trap-time esp
trap-time eflags
trap-time eip
trap-time eax       start of struct PushRegs
trap-time ecx
trap-time edx
trap-time ebx
trap-time esp
trap-time ebp
trap-time esi
trap-time edi       end of struct PushRegs
tf_err (error code)
fault_va            <-- %esp when handler is run
```

​		然后，内核安排用户环境在异常堆栈上使用该堆栈帧运行页面错误处理程序来恢复执行;你必须想办法让这一切发生。fault_va是导致页面错误的虚拟地址。

​		如果在发生异常时，用户环境已经在用户异常堆栈上运行，则页面错误处理程序本身已经出错。在这种情况下，应该在当前tf->tf_esp下而不是在UXSTACKTOP上启动新的堆栈帧。我们应该首先推动一个空的32位字，然后是一个struct UTrapframe。

​		要测试tf->tf_esp是否已经在用户异常堆栈上，请检查它是否在UXSTACKTOP-PGSIZE和UXSTACKTOP-1(包括UXSTACKTOP-1)之间。

### 练习9

在kern/trap.c中实现page_fault_handler中的代码，这是将页面错误分配给用户模式处理程序所必需的。在写入异常堆栈时，请确保采取适当的预防措施。

```c
void
page_fault_handler(struct Trapframe *tf)
{
	uint32_t fault_va;

	// Read processor's CR2 register to find the faulting address
	fault_va = rcr2();

	// Handle kernel-mode page faults.

	// LAB 3: Your code here.
	if ((tf->tf_cs & 3) == 0) {
        	panic("kernel page fault at:%x\n", fault_va);
    	}   
	// 我们已经处理了内核模式异常，所以如果我们到这里，页面错误发生在用户模式。

	// 如果存在页面错误向上调用，则调用该环境的页面错误向上调用。在用户异常堆栈(UXSTACKTOP下面)上设置一个页面错误堆栈框架，然后转移到curenv-&gt;env_pgfault_upcall。
	//
	// 页面错误向上调用可能会导致另一个页面错误，在这种情况下，我们递归地转移到页面错误向上调用，将另一个页面错误堆栈框架推到用户异常堆栈的顶部。
	//
	// 对于从页面错误(lib/ pfentre . s)返回的代码来说，在捕获时间堆栈的顶部有一个空白字是很方便的;它使我们更容易地恢复eip/esp。在非递归的情况下，我们不必担心这个问题，因为常规用户堆栈的顶部是空闲的。在递归的情况下，这意味着我们必须在异常堆栈的当前顶部和新的堆栈框架之间留下一个额外的字，因为异常堆栈是捕获时堆栈。
	//
	// 如果没有页面错误向上调用，环境没有为其异常堆栈分配页面，或者无法向其写入，或者异常堆栈溢出，则破坏导致错误的环境。请注意，等级脚本假设您将首先检查页面错误向上调用，如果没有，则在下面打印“user fault va”消息。剩下的三个检查可以合并成一个测试。
	//
	// Hints:
	// user_mem_assert()和env_run()在这里很有用。要更改用户环境运行的内容，请修改'curenv-&gt;env_tf' ('tf'变量指向'curenv-&gt;env_tf')。

	// LAB 4: Your code here.
	if (curenv->env_pgfault_upcall) {
        struct UTrapframe *utf;
        if (tf->tf_esp >= UXSTACKTOP-PGSIZE && tf->tf_esp <= UXSTACKTOP-1) {
            utf = (struct UTrapframe *)(tf->tf_esp - sizeof(struct UTrapframe) - 4); 
        } else {
            utf = (struct UTrapframe *)(UXSTACKTOP - sizeof(struct UTrapframe));
        }   

        user_mem_assert(curenv, (void*)utf, 1, PTE_W);
        utf->utf_fault_va = fault_va;
        utf->utf_err = tf->tf_err;
        utf->utf_regs = tf->tf_regs;
        utf->utf_eip = tf->tf_eip;
        utf->utf_eflags = tf->tf_eflags;
        utf->utf_esp = tf->tf_esp;

        curenv->env_tf.tf_eip = (uintptr_t)curenv->env_pgfault_upcall;
        curenv->env_tf.tf_esp = (uintptr_t)utf;
        env_run(curenv);
    } 
	// Destroy the environment that caused the fault.
	cprintf("[%08x] user fault va %08x ip %08x\n",
		curenv->env_id, fault_va, tf->tf_eip);
	print_trapframe(tf);
	env_destroy(curenv);
}
```

