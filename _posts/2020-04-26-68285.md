---
layout:     post   				    # 使用的布局（不需要改）
title:      6828-lab5	(5.1更新)	# 标题 
#subtitle:   脚本，xss #副标题
date:       2020-04-26 				# 时间
author:     s-seven 						# 作者
header-img: img/post-bg-2015.jpg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - 6828
---

在这个实验中，我们将实现spawn，一个加载并运行磁盘上可执行文件的库调用。然后，我们将充实您的内核和库操作系统，使其足以在控制台上运行shell。这些特性需要一个文件系统，本实验介绍了一个简单的读/写文件系统。

# Lab5 File system, Spawn and Shell

切换分支获取新文件：

| `fs/fs.c`       | Code that mainipulates the file system's on-disk structure.  |
| --------------- | ------------------------------------------------------------ |
| `fs/bc.c`       | A simple block cache built on top of our user-level page fault handling facility. |
| `fs/ide.c`      | Minimal PIO-based (non-interrupt-driven) IDE driver code.    |
| `fs/serv.c`     | The file system server that interacts with client environments using file system IPCs. |
| `lib/fd.c`      | Code that implements the general UNIX-like file descriptor interface. |
| `lib/file.c`    | The driver for on-disk file type, implemented as a file system IPC client. |
| `lib/console.c` | The driver for console input/output file type.               |
| `lib/spawn.c`   | Code skeleton of the `spawn` library call.                   |

## File system preliminaries

​		我们将使用的文件系统比大多数“真正的”文件系统(包括xv6 UNIX)要简单得多，但是它的功能已经足够强大，可以提供基本功能:创建、读取、写入和删除按层次目录结构组织的文件。

​		我们(至少目前)只开发一个单用户操作系统，它提供的保护足以捕获bug，但不能保护多个相互怀疑的用户。因此，我们的文件系统不支持文件所有权或权限的UNIX概念。我们的文件系统目前也不像大多数UNIX文件系统那样支持硬链接、符号链接、时间戳或特殊设备文件。

### 磁盘上的文件系统结构

​		大多数UNIX文件系统将可用的磁盘空间划分为两种主要的区域类型:inode区域和数据区域。UNIX文件系统为文件系统中的每个文件分配一个inode;文件的inode保存关于文件的关键元数据，如其stat属性和指向其数据块的指针。数据区域被划分为更大的数据块(通常为8KB或更多)，文件系统在这些数据块中存储文件数据和目录元数据。目录项包含文件名和指向索引节点的指针;如果文件系统中的多个目录项引用该文件的inode，则称该文件为硬链接。因为我们的文件系统不支持硬链接,我们不需要这种级别的间接寻址,因此可以方便的简化:我们的文件系统不会使用索引节点,而不是只会存储所有的文件(或目录)的元数据(唯一的)中描述该文件的目录条目。

​		文件和目录在逻辑上都由一系列数据块组成，这些数据块可以分散在磁盘上，就像环境的虚拟地址空间的页面可以分散在物理内存中一样。文件系统环境隐藏了块布局的细节，提供了在文件中任意偏移量处读取和写入字节序列的接口。文件系统环境在内部处理对目录的所有修改，作为执行诸如文件创建和删除等操作的一部分。我们的文件系统允许用户环境直接读取目录元数据(例如，使用read)，这意味着用户环境可以自己执行目录扫描操作(例如，实现ls程序)，而不必依赖于对文件系统的额外特殊调用。这种目录扫描方法的缺点(也是大多数现代UNIX变体不支持这种方法的原因)是，它使应用程序依赖于目录元数据的格式，使更改文件系统的内部布局变得非常困难，除非更改或至少重新编译应用程序。

#### Sectors and Blocks

​		大多数磁盘不能按字节粒度执行读写操作，而是以扇区为单位执行读写操作。在JOS中，每个扇区是512字节。文件系统实际上是以块为单位分配和使用磁盘存储的。注意这两个术语之间的区别:扇区大小是磁盘硬件的属性，而块大小是使用磁盘的操作系统的一个方面。文件系统的块大小必须是基础磁盘扇区大小的倍数。

​		UNIX xv6文件系统使用512字节的块大小，与底层磁盘的扇区大小相同。然而，大多数现代文件系统使用更大的块大小，因为存储空间变得更便宜，而且在更大的粒度上管理存储更有效。我们的文件系统将使用一个4096字节的块大小，方便地匹配处理器的页面大小。

#### Superblocks

​		文件系统通常留出一定数量的磁盘块在磁盘上的“填充”位置(比如一开始或结尾)来保存元数据描述的属性文件系统作为一个整体,如块大小、磁盘大小,任何需要查找根目录的元数据,去年挂载文件系统时,文件系统是上次的时间错误,等等。这些特殊的块被称为超级块。

​		我们的文件系统将只有一个超级块，它总是在磁盘上的第1块。它的布局是由struct Super在inc/fs.h中定义的。块0通常保留用于保存引导加载程序和分区表，因此文件系统通常不使用第一个磁盘块。许多“真正的”文件系统维护多个超级块，这些超级块被复制到磁盘的多个宽空间区域，因此，如果其中一个被破坏或磁盘在该区域出现媒体错误，仍然可以找到其他超级块，并使用它们访问文件系统。

![Disk layout](https://pdos.csail.mit.edu/6.828/2018/labs/lab5/disk.png)

![File structure](https://pdos.csail.mit.edu/6.828/2018/labs/lab5/file.png)

#### File Meta-data

​		在我们的文件系统中，描述文件的元数据的布局由inc/fs.h中的结构文件描述。这个元数据包括文件的名称、大小、类型(常规文件或目录)和指向组成文件的块的指针。如上所述，我们没有inode，所以这个元数据存储在磁盘上的目录条目中。与大多数“真实的”文件系统不同，为了简单起见，我们将使用这个文件结构来表示在磁盘和内存中出现的文件元数据。

​		结构文件中的f_direct数组包含存储文件的前10个(NDIRECT)块的块号的空间，我们称之为文件的direct块。对于大小为10*4096 = 40KB的小文件，这意味着所有文件块的块号将直接适合文件结构本身。但是，对于较大的文件，我们需要一个地方来存放文件的其余块号。因此，对于任何大于40KB的文件，我们将分配一个额外的磁盘块，称为文件的间接块，以容纳最多4096/4 = 1024个额外的块号。因此，我们的文件系统允许文件的大小最多为1034块，即超过4兆字节。为了支持更大的文件，“真正的”文件系统通常还支持双间接块和三间接块。

#### Directories versus Regular Files

​		在我们的文件系统中，一个文件结构既可以表示一个普通文件，也可以表示一个目录;这两种类型的“文件”是由文件结构中的类型字段来区分的。文件系统管理常规文件和目录文件以完全相同的方式,除了它不解释的内容与常规文件相关联的数据块,而文件系统目录文件的内容解释为一系列的文件结构描述的目录中的文件和子目录。

​		我们的文件系统中的超块包含一个文件结构(struct Super中的根字段)，它保存文件系统根目录的元数据。这个目录文件的内容是描述文件系统根目录中的文件和目录的文件结构序列。根目录中的任何子目录都可能包含更多表示子目录的文件结构，等等。

## 文件系统

​		这个实验的目标不是让我们实现整个文件系统，而是让我们只实现某些关键组件。特别是，我们将负责将块读入块缓存并将它们刷新回磁盘;分配磁盘块;将文件偏移量映射到磁盘块;并在IPC接口中实现读、写和打开。因为我们不会自己实现所有的文件系统，所以熟悉所提供的代码和各种文件系统接口是非常重要的。

### 磁盘访问

​		我们的操作系统中的文件系统环境需要能够访问磁盘，但是我们还没有在内核中实现任何磁盘访问功能。我们没有采用传统的“单片”操作系统策略，即在内核中添加一个IDE磁盘驱动程序以及必要的系统调用以允许文件系统访问它，而是将IDE磁盘驱动程序实现为用户级文件系统环境的一部分。我们仍然需要稍微修改内核，以便进行设置，使文件系统环境拥有实现磁盘访问本身所需的特权。

​		只要我们依赖于轮询、基于“已编程I/O”(PIO)的磁盘访问，并且不使用磁盘中断，就很容易在用户空间中实现磁盘访问。也可以在用户模式下实现中断驱动的设备驱动程序(例如，L3和L4内核实现了这一点)，但是难度更大，因为内核必须字段设备中断并将它们分派到正确的用户模式环境中。

​		x86处理器使用EFLAGS寄存器中的IOPL位来确定是否允许受保护模式代码执行特殊的设备I/O指令，例如in和OUT指令。由于我们需要访问的所有IDE磁盘寄存器都位于x86的I/O空间中，而不是被映射到内存中，因此为了允许文件系统访问这些寄存器，我们只需要将“I/O特权”授予文件系统环境。实际上，EFLAGS寄存器中的IOPL位为内核提供了一个简单的“全有或全无”方法来控制用户模式代码是否可以访问I/O空间。在我们的示例中，我们希望文件系统环境能够访问I/O空间，但是我们根本不希望任何其他环境能够访问I/O空间。

####练习1

i386_init通过将类型ENV_TYPE_FS传递给环境创建函数env_create来标识文件系统环境。在env.c中修改env_create。因此，它赋予文件系统环境I/O特权，但从不将此特权授予任何其他环境。

```C
// 用env_alloc分配一个新的env，用load_icode加载命名的elf二进制文件，并设置它的env_type。此函数仅在运行第一个用户模式环境之前的内核初始化期间调用。新环境的父ID设置为0。
void
env_create(uint8_t *binary, enum EnvType type)
{
	// LAB 3: Your code here.


	// If this is the file server (type == ENV_TYPE_FS) give it I/O privileges.
	// LAB 5: Your code here.

	struct Env *e;
	int r;
	if ((r = env_alloc(&e, 0) != 0)) {
		panic("create env failed\n");
	}
	if (type == ENV_TYPE_FS) {
		e->env_tf.tf_eflags |= FL_IOPL_MASK;
	}

	load_icode(e, binary);
	e->env_type = type;

}
```

测试一下：

[![JcFVJ0.jpg](https://s1.ax1x.com/2020/04/26/JcFVJ0.jpg)](https://imgchr.com/i/JcFVJ0)

##块缓存

​		在我们的文件系统中，我们将在处理器的虚拟内存系统的帮助下实现一个简单的“缓冲区缓存”(实际上就是块缓存)。块缓存的代码在fs/bc.c中。

​		我们的文件系统将仅限于处理3GB或更小的磁盘。我们保留文件系统环境的地址空间的一个大的、固定的3GB区域，从0x10000000 (DISKMAP)到0xD0000000 (DISKMAP+DISKMAX)，作为磁盘的“内存映射”版本。例如，将磁盘块0映射到虚拟地址0x10000000，将磁盘块1映射到虚拟地址0x10001000，等等。fs/bc.c中的diskaddr函数实现了从磁盘块号到虚拟地址的转换(以及一些完整性检查)。

​		环境因为我们的文件系统有它自己的虚拟地址空间独立的虚拟地址空间中的所有其他环境系统,和文件系统环境需要做的唯一的事是实现文件访问,它是合理的储备的大部分文件系统环境的地址空间。对于32位机器上的实际文件系统实现来说，这样做会很尴尬，因为现代磁盘大于3GB。这样的缓冲区缓存管理方法在64位地址空间的机器上仍然是合理的。

​		当然,需要很长一段时间整个磁盘读取到内存中,所以我们请求分页的实现形式,其中我们只在磁盘分配页地图区域和从磁盘读取相应的块来响应一个页面错误在这个地区。这样，我们就可以假设整个磁盘都在内存中。

### 练习2

​		在fs/bc.c中实现bc_pgfault和flush_block函数。bc_pgfault是一个页面错误处理程序，就像我们在前一个实验中为写时复制分支编写的处理程序一样，只是它的工作是从磁盘加载页面以响应页面错误。在编写这篇文章时，请记住(1)addr可能不与块边界对齐，(2)ide_read在扇区而不是块中操作。

​		如果需要，flush_block函数应该将一个块写到磁盘上。如果块甚至不在块缓存中(也就是说，页面没有被映射)，或者它不是脏的，那么flush_block不应该执行任何操作。我们将使用VM硬件跟踪磁盘块是否在最后一次从磁盘读取或写入磁盘之后被修改。要查看一个块是否需要写入，我们可以查看是否在uvpt条目中设置了PTE_D“dirty”位。(PTE_D位是处理器在对该页进行写操作时设置的;见386参考手册第5章5.2.4.3。)在将块写入磁盘之后，flush_block应该使用sys_page_map清除PTE_D位。

```C
// 通过从磁盘加载读到内存的任何磁盘块发生故障。
static void
bc_pgfault(struct UTrapframe *utf)
{
	void *addr = (void *) utf->utf_fault_va;
	uint32_t blockno = ((uint32_t)addr - DISKMAP) / BLKSIZE;
	int r;

	// Check that the fault was within the block cache region
	if (addr < (void*)DISKMAP || addr >= (void*)(DISKMAP + DISKSIZE))
		panic("page fault in FS: eip %08x, va %08x, err %04x",
		      utf->utf_eip, addr, utf->utf_err);

	// Sanity check the block number.
	if (super && blockno >= super->s_nblocks)
		panic("reading non-existent block %08x\n", blockno);

	// 在磁盘映射区域中分配一个页，将块的内容从磁盘读入该页。
	// 提示:第一轮添加到页面边界。fs/ide.c有读取磁盘的代码
	// LAB 5: you code here:
	addr = ROUNDDOWN(addr, PGSIZE);
	sys_page_alloc(0, addr, PTE_W|PTE_U|PTE_P);
	if ((r = ide_read(blockno * BLKSECTS, addr, BLKSECTS)) < 0)
		panic("ide_read: %e", r);
	// Clear the dirty bit for the disk block page since we just read the
	// block from disk
	if ((r = sys_page_map(0, addr, 0, addr, uvpt[PGNUM(addr)] & PTE_SYSCALL)) < 0)
		panic("in bc_pgfault, sys_page_map: %e", r);

	// Check that the block we read was allocated. (exercise for
	// the reader: why do we do this *after* reading the block
	// in?)
	if (bitmap && block_is_free(blockno))
		panic("reading free block %08x\n", blockno);
}
```

```C
// 如果需要，将包含VA的块的内容清除到磁盘，然后使用sys_page_map清除PTE_D位。如果块不在块缓存中或不是脏的，则什么也不做。
// 提示:使用va_is_mapped, va_is_dirty和ide_write。
// 提示:在调用sys_page_map时使用PTE_SYSCALL常量。
// 提示:别忘了把地址四舍五入。
void
flush_block(void *addr)
{
	uint32_t blockno = ((uint32_t)addr - DISKMAP) / BLKSIZE;
	int r;
	if (addr < (void*)DISKMAP || addr >= (void*)(DISKMAP + DISKSIZE))
		panic("flush_block of bad va %08x", addr);

	// LAB 5: Your code here.
	addr = ROUNDDOWN(addr, PGSIZE);
	if (!va_is_mapped(addr) || !va_is_dirty(addr)) {		//如果addr还没有映射过或者该页载入到内存后还没有被写过，不用做任何事
		return;
	}
	if ((r = ide_write(blockno * BLKSECTS, addr, BLKSECTS)) < 0) {		//写回到磁盘
		panic("in flush_block, ide_write(): %e", r);
	}
	if ((r = sys_page_map(0, addr, 0, addr, uvpt[PGNUM(addr)] & PTE_SYSCALL)) < 0)	//清空PTE_D位
		panic("in bc_pgfault, sys_page_map: %e", r);
	//panic("flush_block not implemented");
}
```

测试一下

[![Jh37uT.jpg](https://s1.ax1x.com/2020/04/27/Jh37uT.jpg)](https://imgchr.com/i/Jh37uT)

## The Block Bitmap

​		在fs_init设置了位图指针之后，我们可以将位图视为一个打包的位数组，每个位对应磁盘上的每个块。例如，block_is_free，它只是检查给定块在位图中是否标记为free。

### 练习3

使用free_block作为模型在fs/fs中实现alloc_block。它应该在位图中找到一个空闲的磁盘块，标记它已使用，并返回该块的编号。当您分配一个块时，您应该立即使用flush_block将更改后的位图块刷新到磁盘，以帮助保持文件系统的一致性。

```C
//在位图中搜索一个空闲块并分配它。当您分配一个块时，立即将更改后的位图块刷新到磁盘。
//返回成功分配的块号，
//提示:使用free_block作为操作位图的例子。
int
alloc_block(void)
{
	// 位图由一个或多个块组成。单个位图块包含BLKBITSIZE块正在使用的位。磁盘中总共有超>s_nblocks块。
	// LAB 5: Your code here.
	uint32_t bmpblock_start = 2;
	for (uint32_t blockno = 0; blockno < super->s_nblocks; blockno++) {
		if (block_is_free(blockno)) {					//搜索free的block
			bitmap[blockno / 32] &= ~(1 << (blockno % 32));		//标记为已使用
			flush_block(diskaddr(bmpblock_start + (blockno / 32) / NINDIRECT));	//将刚刚修改的bitmap block写到磁盘中
			return blockno;
		}
	}
	return -E_NO_DISK;
	//panic("alloc_block not implemented");
}
```

## File Operations

我们在fs/fs.c中提供了各种函数来实现基本功能，我们将需要这些功能来解释和管理文件结构、扫描和管理目录文件的条目，以及从根目录遍历文件系统来解析绝对路径名。请通读fs/fs.c中的所有代码，并确保在继续之前了解每个函数的功能。

### 练习4

实现file_block_walk和file_get_block。file_block_walk从文件中的块偏移量映射到结构文件或间接块中的块指针，非常类似于pgdir_walk对页表所做的映射。file_get_block进一步映射到实际的磁盘块，并在必要时分配一个新的磁盘块。

```C
// 找到文件f中“filebno”第一个块的磁盘块号槽。设置'*ppdiskbno'指向该插槽。这个槽将是f->f_direct[]项中的一个，或者是间接块中的一个项。当'alloc'被设置时，这个函数将在必要时分配一个间接块。
// 提示:不要忘记清除你分配的任何块。
static int
file_block_walk(struct File *f, uint32_t filebno, uint32_t **ppdiskbno, bool alloc)
{
       // LAB 5: Your code here.
	int bn;
	uint32_t *indirects;
	if (filebno >= NDIRECT + NINDIRECT)
		return -E_INVAL;

	if (filebno < NDIRECT) {
		*ppdiskbno = &(f->f_direct[filebno]);
	} else {
		if (f->f_indirect) {
			indirects = diskaddr(f->f_indirect);
			*ppdiskbno = &(indirects[filebno - NDIRECT]);
		} else {
			if (!alloc)
				return -E_NOT_FOUND;
			if ((bn = alloc_block()) < 0)
				return bn;
			f->f_indirect = bn;
			flush_block(diskaddr(bn));
			indirects = diskaddr(bn);
			*ppdiskbno = &(indirects[filebno - NDIRECT]);
		}
	}

	return 0;
       //panic("file_block_walk not implemented");
}
```

```C
// 将*blk设置为文件f的filebno第一个块映射到的内存地址。
// 提示:使用文件块walk和alloc块。
int
file_get_block(struct File *f, uint32_t filebno, char **blk)
{
       // LAB 5: Your code here.
	int r;
	   	uint32_t *pdiskbno;
	   	if ((r = file_block_walk(f, filebno, &pdiskbno, true)) < 0) {
		  	return r;
	   	}

		int bn;
		if (*pdiskbno == 0) {			//此时*pdiskbno保存着文件f第filebno块block的索引
			if ((bn = alloc_block()) < 0) {
				return bn;
			}
			*pdiskbno = bn;
			flush_block(diskaddr(bn));
		}
		*blk = diskaddr(*pdiskbno);
	   	return 0;
       //panic("file_get_block not implemented");
}
```

file_block_walk和file_get_block是文件系统的主力。例如，file_read和file_write只不过是在file_get_block上进行簿记，这是在分散的块和连续的缓冲区之间复制字节所必需的。

## The file system interface

​		既然我们已经在文件系统环境本身中拥有了必要的功能，那么我们必须让希望使用文件系统的其他环境也可以访问它。由于其他环境不能直接调用文件系统环境中的函数，所以我们将通过构建在JOS IPC机制之上的远程过程调用(RPC)抽象来公开对文件系统环境的访问。从图形上看，下面是对文件系统服务器(比如read)的调用

[![JoXXfs.jpg](https://s1.ax1x.com/2020/04/29/JoXXfs.jpg)](https://imgchr.com/i/JoXXfs)

​		虚线以下的内容只是将一个读请求从常规环境获取到文件系统环境的机制。从一开始，read(我们提供)就可以在任何文件描述符上工作，并简单地分派给适当的设备读函数，在本例中是devfile_read(我们可以有更多的设备类型，比如管道)。devfile_read实现了专门针对磁盘文件的读取。lib/file.c中的这个函数和其他devfile_*函数实现了FS操作的客户端，它们以大致相同的方式工作，在请求结构中绑定参数，调用fsipc发送IPC请求，然后解包并返回结果。fsipc函数只处理向服务器发送请求和接收应答的常见细节。

​		文件系统服务器代码可以在fs/ server .c中找到。它在serve函数中循环，不断地通过IPC接收请求，将请求发送给适当的处理程序函数，然后通过IPC将结果发送回来。在read示例中，serve将分派给serve_read，它将处理特定于读请求的IPC细节，比如解包请求结构并最终调用file_read来实际执行文件读取。

​		回想一下，JOS的IPC机制允许环境发送一个32位的数字，并可选地共享一个页面。为了将请求从客户机发送到服务器，我们使用32位的数字作为请求类型(文件系统服务器rpc编号，就像syscalls编号一样)，并将请求的参数存储在通过IPC共享的页面上的union Fsipc中。在客户端，我们总是在fsipcbuf共享页面;在服务器端，我们将传入的请求页面映射到fsreq (0x0ffff000)。

​		服务器还通过IPC发回响应。我们使用32位数字作为函数的返回代码。对于大多数rpc，这是它们返回的所有内容。FSREQ_READ和FSREQ_STAT也返回数据，它们只是将数据写入客户机发送请求的页面。不需要在响应IPC中发送此页面，因为客户端首先与文件系统服务器共享此页面。同样，在它的响应中，FSREQ_OPEN与客户端共享一个新的“Fd页面”。我们将很快返回到文件描述符页面。

### 练习5

在fs/ serv .c中实现serve_read。

serve_read的繁重工作将由fs/fs.c中已经实现的file_read来完成(而这只是对file_get_block的一系列调用)。serve_read只需提供用于文件读取的RPC接口。查看serve_set_size中的注释和代码，大致了解应该如何构造服务器函数。

```C
// 读ipc- gt;读req_n字节来自ipc中的当前查找位置- gt;read.req_fileid。在ipc- gt;readRet中将从文件中读取的字节返回给调用者，然后更新查找位置。返回成功读取的字节数，或&lt;0错误。
int
serve_read(envid_t envid, union Fsipc *ipc)
{
	struct Fsreq_read *req = &ipc->read;
	struct Fsret_read *ret = &ipc->readRet;

	if (debug)
		cprintf("serve_read %08x %08x %08x\n", envid, req->req_fileid, req->req_n);

	// Lab 5: Your code here:
	struct OpenFile *o;
	int r;
	r = openfile_lookup(envid, req->req_fileid, &o);
	if (r < 0)		//通过fileid找到Openfile结构
		return r;
	if ((r = file_read(o->o_file, ret->ret_buf, req->req_n, o->o_fd->fd_offset)) < 0)	//调用fs.c中函数进行真正的读操作
		return r;
	o->o_fd->fd_offset += r;
	
	return r;
	//return 0;
}
```

### 练习6

在fs/ serv .c中实现serve_write，在lib/file.c中实现devfile_write。

```C
// 从req-&gt;req_buf写入req-&gt;req_n字节到req_fileid，从当前的查找位置开始，并相应地更新查找位置。必要时扩展文件。
int
serve_write(envid_t envid, struct Fsreq_write *req)
{
	if (debug)
		cprintf("serve_write %08x %08x %08x\n", envid, req->req_fileid, req->req_n);

	// LAB 5: Your code here.
	struct OpenFile *o;
	int r;
	if ((r = openfile_lookup(envid, req->req_fileid, &o)) < 0) {
		return r;
	}
	int total = 0;
	while (1) {
		r = file_write(o->o_file, req->req_buf, req->req_n, o->o_fd->fd_offset);
		if (r < 0) return r;
		total += r;
		o->o_fd->fd_offset += r;
		if (req->req_n <= total)
			break;
	}
	return total;
	//panic("serve_write not implemented");
}
```

```C
// 在当前查找位置上从'buf'写入最多'n'字节到'fd'。
static ssize_t
devfile_write(struct Fd *fd, const void *buf, size_t n)
{
	// 向文件系统服务器发出FSREQ_WRITE请求。小心:fsipcbuf.write。req_buf只是这么大，但是请记住，总是允许写入比请求的*更少的*字节。
	// LAB 5: Your code here
	int r;
	fsipcbuf.write.req_fileid = fd->fd_file.id;
	fsipcbuf.write.req_n = n;
	memmove(fsipcbuf.write.req_buf, buf, n);
	return fsipc(FSREQ_WRITE, NULL);
	//panic("devfile_write not implemented");
}
```

## Spawning Processes

​		我们已经为spawn(参见lib/spawn.c)提供了代码，它创建了一个新环境，从文件系统加载一个程序映像到其中，然后启动运行这个程序的子环境。然后父进程继续独立于子进程运行。spawn函数在UNIX中有效地充当一个fork，然后在子进程中直接执行exec。

​		我们实现了spawn而不是一个unix风格的exec，因为spawn更容易实现从用户空间在“exokernel的方式”，没有特别的帮助，从内核。考虑一下要在用户空间中实现exec需要做什么，并确保您理解为什么这么做比较困难。

### 练习7

spawn依赖于新的syscall sys_env_set_trapframe来初始化新创建环境的状态。在kern/syscall.c中实现sys_env_set_trapframe(不要忘记在syscall()中调度新系统调用)。

```c
static int
sys_env_set_trapframe(envid_t envid, struct Trapframe *tf)
{
	// LAB 5: Your code here.
	// 记得要检查用户是否给我们提供了一个正确的地址!
	int r;
	struct Env *e;
	if ((r = envid2env(envid, &e, 1)) < 0) {
		return r;
	}
	tf->tf_eflags = FL_IF;
	tf->tf_eflags &= ~FL_IOPL_MASK;			//普通进程不能有IO权限
	tf->tf_cs = GD_UT | 3;
	e->env_tf = *tf;
	return 0;
}
```

## Sharing library state across fork and spawn

​		UNIX文件描述符是一个通用概念，它还包括管道、控制台I/O等。在JOS中，每种设备类型都有一个对应的struct Dev，带有指向实现读/写/等功能的指针。对于那个设备类型。lib/ fdc在此基础上实现了通用的类unix文件描述符接口。每个struct Fd都指示其设备类型，lib/ fdc中的大多数函数只是简单地将操作分派给适当的struct Dev中的函数。

​		lib/ fdc还在每个应用程序环境的地址空间中维护文件描述符表区域，从FDTABLE开始。这个区域为应用程序可以同时打开的最大MAXFD(当前为32)文件描述符保留了一个页面大小(4KB)的地址空间。在任何给定时间，当且仅当使用相应的文件描述符时，映射特定的文件描述符表页。每个文件描述符在从FILEDATA开始的区域中还有一个可选的“数据页”，如果设备愿意，可以使用这些数据页。

​		我们希望共享文件描述符，JOS中定义PTE新的标志位PTE_SHARE，如果有个页表条目的PTE_SHARE标志位为1，那么这个PTE在fork()和spawn()中将被直接拷贝到子进程页表，从而让父进程和子进程共享相同的页映射关系，从而达到父子进程共享文件描述符的目的。

### 练习8

修改lib/fork.c中的duppage()，使之正确处理有PTE_SHARE标志的页表条目。同时实现lib/spawn.c中的copy_shared_pages()。

```C
static int
duppage(envid_t envid, unsigned pn)
{
	int r;

	// LAB 4: Your code here.
	void *addr = (void*) (pn * PGSIZE);
	if (uvpt[pn] & PTE_SHARE) {
		sys_page_map(0, addr, envid, addr, PTE_SYSCALL);		//对于标识为PTE_SHARE的页，拷贝映射关系，并且两个进程都有读写权限
	} else if ((uvpt[pn] & PTE_W) || (uvpt[pn] & PTE_COW)) { //对于UTOP以下的可写的或者写时拷贝的页，拷贝映射关系的同时，需要同时标记当前进程和子进程的页表项为PTE_COW
		if ((r = sys_page_map(0, addr, envid, addr, PTE_COW|PTE_U|PTE_P)) < 0)
			panic("sys_page_map：%e", r);
		if ((r = sys_page_map(0, addr, 0, addr, PTE_COW|PTE_U|PTE_P)) < 0)
			panic("sys_page_map：%e", r);
	} else {
		sys_page_map(0, addr, envid, addr, PTE_U|PTE_P);	//对于只读的页，只需要拷贝映射关系即可
	}
	return 0;
}
```

```C
static int
copy_shared_pages(envid_t child)
{
	// LAB 5: Your code here.
	uintptr_t addr;
	for (addr = 0; addr < UTOP; addr += PGSIZE) {
		if ((uvpd[PDX(addr)] & PTE_P) && (uvpt[PGNUM(addr)] & PTE_P) &&
				(uvpt[PGNUM(addr)] & PTE_U) && (uvpt[PGNUM(addr)] & PTE_SHARE)) {
            sys_page_map(0, (void*)addr, child, (void*)addr, (uvpt[PGNUM(addr)] & PTE_SYSCALL));
        }
	}
	return 0;
}
```

